{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12259712,"sourceType":"datasetVersion","datasetId":7725383}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Modele de classification des messages haineux et non haineux dans le contexte Camerounais\n\n### TCHIAZE FOUOSSO ROMERO\n### NDONKOU FRANCK\n### ENGOULOU GAETAN","metadata":{}},{"cell_type":"code","source":"\n# --- √âtape 0 : Installation des D√©pendances Compatibles et Red√©marrage ---\n# Ex√©cutez cette cellule UNE SEULE FOIS au d√©but de votre session.\n# Elle va forcer le red√©marrage du noyau, ce qui est NORMAL.\n# Apr√®s le red√©marrage, ne la r√©-ex√©cutez pas et passez √† la cellule suivante.\nimport os\n\nprint(\"Installation des versions de biblioth√®ques compatibles pour un entra√Ænement stable...\")\n# On utilise un ensemble de versions connues pour bien fonctionner ensemble.\n# `transformers==4.41.2` est une version stable qui fonctionne bien avec `peft` r√©cent.\n!pip install transformers==4.41.2 datasets==2.19.1 sentencepiece==0.2.0 accelerate==0.30.1 peft==0.10.0 scikit-learn seaborn -q\nprint(\"Installation termin√©e.\")\n\nprint(\"\\nRED√âMARRAGE DU KERNEL pour appliquer les changements et nettoyer l'√©tat du GPU...\")\nprint(\"C'est normal. Ne r√©-ex√©cutez pas cette cellule apr√®s le red√©marrage.\")\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model page: https://huggingface.co/Poulpidot/distilcamenbert-french-hate-speech\n\n‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/Poulpidot/distilcamenbert-french-hate-speech)\n\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè","metadata":{}},{"cell_type":"markdown","source":"# Projet de D√©tection de Discours Haineux : Fine-Tuning Avanc√©\n\n**Objectif :** Adapter le mod√®le `Poulpidot/distilcamenbert-french-hate-speech` √† un corpus de textes sp√©cifiques (contenant du vocabulaire camerounais) pour am√©liorer la performance de classification.\n\n**D√©marche en 2 phases :**\n1.  **Phase 1 : Adaptation au Domaine (MLM)**\n    - Entra√Ænement d'un nouveau tokenizer sur notre corpus.\n    - Fine-tuning du mod√®le pr√©-entra√Æn√© via le *Masked Language Modeling* (MLM) pour qu'il apprenne notre vocabulaire.\n2.  **Phase 2 : Fine-tuning pour la Classification**\n    - Utilisation du mod√®le adapt√© en Phase 1 comme base.\n    - Fine-tuning sur la t√¢che de classification binaire (hateful / not_hateful).\n\n**R√©sultats attendus :** Un mod√®le de classification robuste, des visualisations de performance (perte, pr√©cision) et une matrice de confusion pour l'√©valuation finale.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport logging\n\n# Configurer le logging pour plus de verbosit√©\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# √âtape 1 : Installer les d√©pendances n√©cessaires\ntry:\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n    logger.info(\"Transformers d√©j√† install√©.\")\nexcept ImportError:\n    logger.info(\"Installation de transformers et d√©pendances...\")\n    try:\n        !pip install transformers==4.45.2 torch sentencepiece\n        from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n        logger.info(\"Transformers install√© avec succ√®s.\")\n    except Exception as e:\n        logger.error(f\"Erreur lors de l'installation de transformers : {e}\")\n        raise\n\n# D√©finir le nom du mod√®le\nmodel_name = \"Poulpidot/distilcamenbert-french-hate-speech\"\n\n# D√©finir le dossier de sauvegarde (dans /kaggle/working/ pour Kaggle)\noutput_dir = \"/kaggle/working/distilcamenbert_french_hate_speech\"\nos.makedirs(output_dir, exist_ok=True)\nlogger.info(f\"Dossier de sauvegarde cr√©√© ou existant : {output_dir}\")\n\n# √âtape 2 : V√©rifier si le mod√®le existe d√©j√† localement\nrequired_files = ['config.json', 'model.safetensors', 'sentencepiece.bpe.model', 'tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json']\nmodel_exists_locally = all(os.path.exists(os.path.join(output_dir, f)) for f in required_files)\n\nif not model_exists_locally:\n    try:\n        # T√©l√©charger et sauvegarder le tokenizer\n        logger.info(f\"T√©l√©chargement du tokenizer depuis {model_name}...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        tokenizer.save_pretrained(output_dir)\n        logger.info(\"Tokenizer sauvegard√©.\")\n\n        # T√©l√©charger et sauvegarder le mod√®le\n        logger.info(f\"T√©l√©chargement du mod√®le depuis {model_name}...\")\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.save_pretrained(output_dir)\n        logger.info(\"Mod√®le sauvegard√©.\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du t√©l√©chargement ou de la sauvegarde : {e}\")\n        raise\nelse:\n    logger.info(f\"Mod√®le d√©j√† pr√©sent dans {output_dir}. Chargement local.\")\n\n# V√©rifier que les fichiers sont bien sauvegard√©s\nprint(\"Mod√®le et tokenizer sauvegard√©s dans :\", output_dir)\nprint(\"Fichiers pr√©sents :\", os.listdir(output_dir))\n\n# √âtape 3 : Tester le mod√®le localement avec une phrase\ntry:\n    # Charger la pipeline depuis le dossier local\n    logger.info(f\"Chargement de la pipeline depuis {output_dir}...\")\n    pipe = pipeline(\"text-classification\", model=output_dir, tokenizer=output_dir, device=0 if torch.cuda.is_available() else -1)\n\n    # Phrase √† tester\n    phrase = \"Cette personne est vraiment m√©chante et inutile.\"\n\n    # Faire une pr√©diction\n    result = pipe(phrase)\n\n    # Afficher le r√©sultat\n    print(f\"Phrase : {phrase}\")\n    print(f\"Pr√©diction : {result}\")\nexcept Exception as e:\n    logger.error(f\"Erreur lors de l'utilisation de la pipeline : {e}\")\n    raise\n\n# √âtape 4 : Tester avec le tokenizer et le mod√®le directement\ntry:\n    # Charger le tokenizer et le mod√®le localement\n    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n\n    # Tokeniser la phrase\n    inputs = tokenizer(phrase, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=100)\n\n    # √âvaluer le mod√®le\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probs = torch.softmax(logits, dim=-1)\n        label_idx = torch.argmax(probs, dim=-1).item()\n        labels = {0: \"not_hateful\", 1: \"hateful\"}  # Labels confirm√©s pour le mod√®le\n\n    print(f\"Pr√©diction d√©taill√©e : {labels[label_idx]} (probabilit√© : {probs[0][label_idx]:.4f})\")\nexcept Exception as e:\n    logger.error(f\"Erreur lors du test manuel : {e}\")\n    raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"import os\nimport shutil\n\n# Chemin du dossier √† compresser\nfolder_path = \"/kaggle/working/distilcamenbert_french_hate_speech\"\n\n# Nom du fichier ZIP √† cr√©er\nzip_file_name = \"distilcamenbert_french_hate_speech.zip\"\n\n# Compresser le dossier en ZIP\nshutil.make_archive(zip_file_name[:-4], 'zip', folder_path)\n\n# V√©rifier que le fichier ZIP a √©t√© cr√©√©\nprint(\"Fichier ZIP cr√©√© :\", os.path.join(\"/kaggle/working\", zip_file_name))\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport numpy as np\nimport os\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy\n\n# --- GESTION DE L'INSTALLATION (si n√©cessaire) ---\n# Si le mod√®le n'est pas trouv√©, le code suivant tentera de l'installer.\ntry:\n    nlp = spacy.load(\"fr_core_news_sm\")\n    print(\"Mod√®le SpaCy 'fr_core_news_sm' charg√© avec succ√®s.\")\nexcept OSError:\n    print(\"Mod√®le SpaCy 'fr_core_news_sm' non trouv√©. Tentative de t√©l√©chargement...\")\n    try:\n        spacy.cli.download(\"fr_core_news_sm\")\n        nlp = spacy.load(\"fr_core_news_sm\")\n        print(\"Mod√®le t√©l√©charg√© et charg√© avec succ√®s.\")\n    except Exception as e:\n        print(f\"√âchec du t√©l√©chargement automatique du mod√®le SpaCy : {e}\")\n        exit()\n\n# T√©l√©charger les stop words pour le fran√ßais\nnltk.download('stopwords', quiet=True)\nfrench_stopwords = set(stopwords.words('french'))\n\n\n# --- CHEMINS DES FICHIERS ---\ninput_file = \"/kaggle/input/datacamer/dataMessages_filtered\"\noutput_file = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"\n\n# V√©rifier si le fichier d'entr√©e existe\nif not os.path.exists(input_file):\n    print(f\"Erreur : Le fichier {input_file} n'a pas √©t√© trouv√©.\")\n    # Si le chemin est incorrect, cette ligne aide √† trouver le bon.\n    # print(\"V√©rifiez le contenu de /kaggle/input/ :\", os.listdir(\"/kaggle/input/\"))\n    exit()\n\n\n# --- NOUVELLES FONCTIONS DE PR√âTRAITEMENT ---\n# Ces fonctions sont ajout√©es sans modifier les v√¥tres.\n\ndef normalize_repeated_chars(text):\n    \"\"\"Normalise les caract√®res r√©p√©t√©s plus de deux fois. Ex: 'troooop' -> 'troop'.\"\"\"\n    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n\ndef lemmatize_text_spacy(text):\n    \"\"\"\n    Effectue la lemmatisation en utilisant SpaCy.\n    C'est une √©tape plus avanc√©e que la simple suppression de stopwords.\n    Ex: \"les voitures roulaient vite\" -> \"le voiture rouler vite\"\n    \"\"\"\n    # On d√©sactive le parser et la reconnaissance d'entit√©s pour la vitesse.\n    doc = nlp(text, disable=['parser', 'ner'])\n    return \" \".join([token.lemma_ for token in doc])\n\n\n# --- VOS FONCTIONS DE PR√âTRAITEMENT (INCHANG√âES) ---\n\ndef remove_entity(raw_text):\n    entity_regex = r\"&[^\\s;]+;\"\n    return re.sub(entity_regex, \"\", raw_text)\n\ndef change_user(raw_text):\n    regex = r\"@([^ ]+)\"\n    return re.sub(regex, \"user\", raw_text)\n\ndef remove_url(raw_text):\n    url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô]))\"\n    return re.sub(url_regex, '', raw_text)\n\ndef remove_noise_symbols(raw_text):\n    return raw_text.replace('\"', '').replace(\"'\", '').replace(\"!\", '').replace(\"`\", '').replace(\"..\", '')\n\ndef remove_punctuation(text):\n    return \"\".join(c for c in text if c not in string.punctuation)\n\ndef remove_stopwords(text):\n    words = text.split()\n    return ' '.join([word for word in words if word.lower() not in french_stopwords])\n\ndef remove_names(text):\n    try:\n        doc = nlp(text)\n        return ' '.join([token.text for token in doc if token.ent_type_ not in ('PER', 'LOC', 'ORG')])\n    except Exception as e:\n        print(f\"Erreur dans remove_names : {e}\")\n        return text\n\n\n# --- PIPELINE DE PR√âTRAITEMENT INT√âGRANT LES NOUVELLES √âTAPES ---\n\ndef preprocess_text(text):\n    \"\"\"\n    Applique toutes les √©tapes de pr√©traitement, anciennes et nouvelles,\n    dans un ordre logique et optimis√©.\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    \n    # 1. Nettoyage initial (URLs, mentions, entit√©s)\n    text = remove_url(text)\n    text = change_user(text)\n    text = remove_entity(text)\n    \n    # 2. Normalisation du texte\n    text = text.lower()  # Mise en minuscule\n    text = normalize_repeated_chars(text) # NOUVELLE √âTAPE\n    \n    # 3. Lemmatisation (g√®re les formes de mots)\n    # text = lemmatize_text_spacy(text) # NOUVELLE √âTAPE (Optionnelle, puissante mais lente)\n    # NOTE: La lemmatisation est tr√®s puissante mais peut √™tre lente.\n    # Pour commencer, je la laisse comment√©e. D√©commentez-la pour un nettoyage plus profond.\n\n    # 4. Suppression du bruit (symboles, ponctuation)\n    text = remove_noise_symbols(text)\n    text = remove_punctuation(text)\n    \n    # 5. Suppression des mots non pertinents (stopwords, noms)\n    text = remove_stopwords(text)\n    text = remove_names(text)\n    \n    # 6. Nettoyage final des espaces\n    text = ' '.join(text.split())\n    \n    return text\n\n\n# --- FONCTION DE STATISTIQUES (INCHANG√âE) ---\n\ndef compute_statistics(df, text_column, label_column, title_prefix=\"\"):\n    print(f\"\\n=== {title_prefix} Statistiques ===\")\n    print(f\"Nombre total d'exemples : {len(df)}\")\n    \n    class_counts = df[label_column].value_counts()\n    print(\"\\nDistribution des classes :\"); print(class_counts)\n    \n    df['word_count'] = df[text_column].apply(lambda x: len(str(x).split()))\n    print(\"\\nStatistiques sur la longueur des phrases (en mots) :\"); print(df['word_count'].describe())\n    \n    all_words = ' '.join(df[text_column].astype(str)).split()\n    word_freq = Counter(all_words).most_common(10)\n    print(\"\\n10 mots les plus fr√©quents :\"); print(word_freq)\n    \n    plt.figure(figsize=(15, 10))\n    plt.subplot(2, 2, 1)\n    sns.countplot(x=label_column, data=df); plt.title(f\"{title_prefix} Distribution des classes\")\n    \n    plt.subplot(2, 2, 2)\n    plt.hist(df['word_count'], bins=20, edgecolor='black'); plt.title(f\"{title_prefix} Histogramme de la longueur des phrases\")\n    \n    plt.subplot(2, 2, 3)\n    words, freqs = zip(*word_freq)\n    sns.barplot(x=list(freqs), y=list(words)); plt.title(f\"{title_prefix} 10 mots les plus fr√©quents\")\n    \n    plt.tight_layout()\n    plt.savefig(f\"/kaggle/working/statistics_{title_prefix.lower().replace(' ', '_')}.png\")\n    plt.show()\n    \n    df.drop(columns=['word_count'], inplace=True, errors='ignore')\n    return df\n\n\n# --- EX√âCUTION DU SCRIPT ---\n\ntry:\n    df = pd.read_csv(input_file, encoding='utf-8')\nexcept Exception as e:\n    print(f\"Erreur lors de la lecture du fichier {input_file} : {e}\")\n    exit()\n\nif not all(col in df.columns for col in ['message', 'vote_final']):\n    print(\"Erreur : Le fichier CSV doit contenir les colonnes 'message' et 'vote_final'.\")\n    exit()\n\n# √âtape 1 : √âtude statistique avant pr√©traitement\ndf = compute_statistics(df, text_column='message', label_column='vote_final', title_prefix=\"Avant pr√©traitement\")\n\n# √âtape 2 : Pr√©traitement des phrases\nprint(\"\\nApplication du pr√©traitement sur les messages...\")\nfrom tqdm.auto import tqdm\ntqdm.pandas() # Active la barre de progression pour .apply()\ndf['message_cleaned'] = df['message'].progress_apply(preprocess_text)\nprint(\"Pr√©traitement termin√©.\")\n\n# √âtape 3 : √âtude statistique apr√®s pr√©traitement\ndf = compute_statistics(df, text_column='message_cleaned', label_column='vote_final', title_prefix=\"Apr√®s pr√©traitement\")\n\n# √âtape 4 : Sauvegarder le fichier CSV pr√©trait√©\ntry:\n    output_df = df[['message_cleaned', 'vote_final']].rename(columns={'message_cleaned': 'message'})\n    output_df.to_csv(output_file, index=False, encoding='utf-8')\n    print(f\"\\nFichier CSV pr√©trait√© sauvegard√© : {output_file}\")\n    print(\"Aper√ßu des premi√®res lignes :\")\n    print(output_df.head())\nexcept Exception as e:\n    print(f\"Erreur lors de la sauvegarde du fichier {output_file} : {e}\")\n    exit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# D√©finir les chemins des fichiers\ninput_file = \"/kaggle/input/datacamer/dataMessages_filtered\"  # Chemin du fichier d'entr√©e\noutput_file = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"  # Chemin de sortie\n\n# Charger le fichier CSV\ntry:\n    df = pd.read_csv(input_file, encoding='utf-8')\nexcept Exception as e:\n    print(f\"Erreur lors de la lecture du fichier {input_file} : {e}\")\n    exit()\n\n# V√©rifier la structure du fichier\nif not all(col in df.columns for col in ['message', 'vote_final']):\n    print(\"Erreur : Le fichier CSV doit contenir les colonnes 'message' et 'vote_final'.\")\n    exit()\n\n# √âtape 1 : √âtude statistique avant pr√©traitement\ndf = compute_statistics(df, text_column='message', label_column='vote_final', title_prefix=\"Avant pr√©traitement\")\n\n# √âtape 2 : Pr√©traitement des phrases\ndf['message_cleaned'] = df['message'].apply(preprocess_text)\n\n# √âtape 3 : √âtude statistique apr√®s pr√©traitement\ndf = compute_statistics(df, text_column='message_cleaned', label_column='vote_final', title_prefix=\"Apr√®s pr√©traitement\")\n\n# √âtape 4 : Sauvegarder le fichier CSV pr√©trait√©\ntry:\n    output_df = df[['message_cleaned', 'vote_final']].rename(columns={'message_cleaned': 'message'})\n    output_df.to_csv(output_file, index=False, encoding='utf-8')\n    print(f\"\\nFichier CSV pr√©trait√© sauvegard√© : {output_file}\")\n    print(\"Aper√ßu des premi√®res lignes :\")\n    print(output_df.head())\nexcept Exception as e:\n    print(f\"Erreur lors de la sauvegarde du fichier {output_file} : {e}\")\n    exit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 2 : Imports et Configuration (APR√àS RED√âMARRAGE)\n\nimport os\nimport pandas as pd\nimport torch\nimport logging\nfrom tqdm.auto import tqdm\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom transformers import (\n    AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer, DataCollatorForLanguageModeling,\n    EarlyStoppingCallback\n)\nfrom transformers.trainer_callback import TrainerCallback\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Configuration\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# --- D√©finition des Chemins et Param√®tres ---\nBASE_MODEL_DIR = \"/kaggle/working/distilcamenbert_french_hate_speech\"\nDATASET_PATH = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"\nEXTENDED_MODEL_DIR = \"/kaggle/working/distilcamembert_extended\"\nADAPTED_LM_DIR = \"/kaggle/working/distilcamembert_extended_adapted_lm\"\nFINAL_CLASSIFIER_DIR = \"/kaggle/working/final_hate_speech_classifier\"\nMLM_EPOCHS = 15 # √âlev√©, car Early Stopping d√©cidera\nCLASSIFICATION_EPOCHS = 20 # √âlev√©, car Early Stopping d√©cidera\nBATCH_SIZE = 16\nLEARNING_RATE = 5e-6 # Taux d'apprentissage faible et stable\n\nlogger.info(\"Configuration et imports termin√©s.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 1.1 : Extension du Tokenizer et du Mod√®le ---\nlogger.info(\"Phase 1 : Adaptation du mod√®le au langage sp√©cifique.\")\n\nlogger.info(\"Chargement du dataset et du tokenizer original...\")\ndf = pd.read_csv(DATASET_PATH).dropna(subset=['message', 'vote_final'])\ndf['message'] = df['message'].astype(str)\noriginal_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_DIR)\noriginal_vocab = set(original_tokenizer.get_vocab().keys())\n\nlogger.info(\"Identification des mots absents du vocabulaire original...\")\ndef extract_words(text): return set(re.findall(r\"[\\w']+\", text.lower()))\ncorpus_words = set()\nfor text in tqdm(df['message'], desc=\"Analyse du corpus\"): corpus_words.update(extract_words(text))\nnew_tokens = list(corpus_words - original_vocab)\nword_counts = pd.Series(' '.join(df['message'].str.lower()).split()).value_counts()\nnew_tokens_to_add = [token for token in new_tokens if word_counts.get(token, 0) > 1]\n\nlogger.info(f\"Ajout de {len(new_tokens_to_add)} nouveaux mots pertinents au tokenizer.\")\noriginal_tokenizer.add_tokens(new_tokens_to_add)\n\nlogger.info(\"Chargement et redimensionnement du mod√®le de base...\")\nmodel_for_extension = AutoModelForMaskedLM.from_pretrained(BASE_MODEL_DIR)\nmodel_for_extension.resize_token_embeddings(len(original_tokenizer))\n\nlogger.info(f\"Sauvegarde du couple mod√®le/tokenizer √©tendu dans {EXTENDED_MODEL_DIR}...\")\nos.makedirs(EXTENDED_MODEL_DIR, exist_ok=True)\nmodel_for_extension.save_pretrained(EXTENDED_MODEL_DIR)\noriginal_tokenizer.save_pretrained(EXTENDED_MODEL_DIR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 1.2 : Fine-tuning MLM avec Stabilisation, M√©triques et Compatibilit√© Maximale ---\n\n# Imports n√©cessaires pour cette cellule\nimport torch\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom transformers import (\n    TrainerCallback, EarlyStoppingCallback, Trainer, TrainingArguments, \n    __version__ as transformers_version  # Import pour d√©tecter la version\n)\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom packaging import version # Outil pour comparer les versions\n\n# --- Callbacks Personnalis√©s ---\n\nclass ProgressCallback(TrainerCallback):\n    \"\"\"Callback pour afficher une barre de progression tqdm personnalis√©e.\"\"\"\n    def __init__(self, task_name=\"Fine-tuning\"):\n        self.task_name = task_name\n        self.progress_bar = None\n    def on_train_begin(self, args, state, control, **kwargs):\n        self.progress_bar = tqdm(total=state.max_steps, desc=self.task_name)\n    def on_step_end(self, args, state, control, **kwargs):\n        self.progress_bar.update(1)\n        if state.log_history and 'loss' in state.log_history[-1]:\n            loss_value = state.log_history[-1]['loss']\n            if loss_value is not None and not torch.isnan(torch.tensor(loss_value)):\n                self.progress_bar.set_postfix(loss=f\"{loss_value:.4f}\")\n            else:\n                self.progress_bar.set_postfix(loss=\"NaN\")\n    def on_train_end(self, args, state, control, **kwargs):\n        if self.progress_bar: self.progress_bar.close()\n\nclass NanLossStopper(TrainerCallback):\n    \"\"\"Callback pour arr√™ter l'entra√Ænement si la perte devient NaN.\"\"\"\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None and 'loss' in logs and (logs['loss'] is None or torch.isnan(torch.tensor(logs['loss']))):\n            logger.error(\"Erreur fatale : Perte NaN d√©tect√©e. Arr√™t de l'entra√Ænement.\")\n            control.should_training_stop = True\n\nclass PerplexityCallback(TrainerCallback):\n    \"\"\"Callback qui calcule et ajoute la perplexit√© aux logs apr√®s chaque √©valuation.\"\"\"\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        # Cette m√©thode est appel√©e chaque fois que des logs sont cr√©√©s.\n        # On v√©rifie si ce sont des logs d'√©valuation (qui contiennent 'eval_loss').\n        if logs is not None and \"eval_loss\" in logs:\n            try:\n                # Calcul de la perplexit√©\n                perplexity = math.exp(logs[\"eval_loss\"])\n                # Ajout de la nouvelle m√©trique au dictionnaire de logs\n                logs[\"eval_perplexity\"] = perplexity\n            except OverflowError:\n                logs[\"eval_perplexity\"] = float(\"inf\")\n\n# --- Pr√©paration du Mod√®le et des Donn√©es ---\nlogger.info(\"Chargement du mod√®le √©tendu pour le fine-tuning MLM...\")\nmlm_model = AutoModelForMaskedLM.from_pretrained(EXTENDED_MODEL_DIR)\nmlm_tokenizer = AutoTokenizer.from_pretrained(EXTENDED_MODEL_DIR)\n\nlogger.info(\"Pr√©paration du dataset pour le MLM...\")\ndataset_mlm = Dataset.from_pandas(df[['message']])\ndef tokenize_function_mlm(examples):\n    return mlm_tokenizer(examples['message'], truncation=True, padding='max_length', max_length=128)\ntokenized_dataset_mlm = dataset_mlm.map(tokenize_function_mlm, batched=True, remove_columns=['message'], desc=\"Tokenizing for MLM\")\ndata_collator_mlm = DataCollatorForLanguageModeling(tokenizer=mlm_tokenizer, mlm=True, mlm_probability=0.15)\ntrain_test_split_mlm = tokenized_dataset_mlm.train_test_split(test_size=0.1, seed=42)\n\n# --- Arguments d'Entra√Ænement avec Gestion de Compatibilit√© ---\ncommon_args = {\n    \"output_dir\": \"/kaggle/working/mlm_results\",\n    \"num_train_epochs\": MLM_EPOCHS,\n    \"learning_rate\": 5e-8,\n    \"per_device_train_batch_size\": 8,\n    \"gradient_accumulation_steps\": 2,\n    \"fp16\": torch.cuda.is_available(),\n    \"max_grad_norm\": 1.0,\n    \"warmup_ratio\": 0.1,\n    \"report_to\": \"none\",\n    \"load_best_model_at_end\": True,\n    \"metric_for_best_model\": \"eval_perplexity\", # La m√©trique que notre callback va ajouter\n    \"greater_is_better\": False, # Pour la perplexit√©, plus bas c'est mieux\n    \"save_total_limit\": 2,\n    \"disable_tqdm\": True,\n    \"seed\": 42\n}\n\nlogger.info(f\"Version de Transformers d√©tect√©e : {transformers_version}\")\nif version.parse(transformers_version) >= version.parse(\"4.20.0\"):\n    logger.info(\"Utilisation de l'API moderne de TrainingArguments (evaluation_strategy).\")\n    training_args_mlm = TrainingArguments(**common_args, evaluation_strategy=\"epoch\", logging_strategy=\"epoch\", save_strategy=\"epoch\")\nelse:\n    logger.warning(\"Utilisation de l'API ancienne de TrainingArguments (eval_steps, logging_steps).\")\n    steps_per_epoch = len(train_test_split_mlm['train']) // (common_args['per_device_train_batch_size'] * common_args['gradient_accumulation_steps'])\n    training_args_mlm = TrainingArguments(**common_args, eval_steps=steps_per_epoch, logging_steps=steps_per_epoch, save_steps=steps_per_epoch)\n\n\n# --- Cr√©ation et Lancement du Trainer ---\ntrainer_mlm = Trainer(\n    model=mlm_model,\n    args=training_args_mlm,\n    train_dataset=train_test_split_mlm['train'],\n    eval_dataset=train_test_split_mlm['test'],\n    data_collator=data_collator_mlm,\n    callbacks=[\n        EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01),\n        ProgressCallback(task_name=\"Fine-tuning (MLM)\"),\n        NanLossStopper(),\n        PerplexityCallback() # Le callback qui va ajouter la m√©trique\n    ]\n)\n\nlogger.info(\"D√©but du fine-tuning MLM (avec calcul de perplexit√© via Callback)...\")\ntrainer_mlm.train()\n\n\n# --- SAUVEGARDE ET VISUALISATION DES M√âTRIQUES ---\nlogger.info(f\"Sauvegarde du meilleur mod√®le adapt√© par MLM dans : {ADAPTED_LM_DIR}\")\ntrainer_mlm.save_model(ADAPTED_LM_DIR)\nmlm_tokenizer.save_pretrained(ADAPTED_LM_DIR)\nlogger.info(\"Phase 1 (Adaptation du langage) termin√©e.\")\n\nlog_history = trainer_mlm.state.log_history\ndf_log = pd.DataFrame(log_history)\n\nif not df_log.empty:\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n    fig.suptitle(\"Performances du Fine-Tuning MLM\", fontsize=16)\n    \n    train_logs = df_log[df_log['loss'].notna()].copy()\n    eval_logs = df_log[df_log['eval_loss'].notna()].copy()\n\n    if not train_logs.empty and not eval_logs.empty:\n        axes[0].plot(train_logs['epoch'], train_logs['loss'], marker='o', label=\"Training Loss\")\n        axes[0].plot(eval_logs['epoch'], eval_logs['eval_loss'], marker='o', label=\"Validation Loss\")\n        axes[0].set_title(\"Perte (Loss)\"); axes[0].set_xlabel(\"√âpoque\"); axes[0].set_ylabel(\"Perte\"); axes[0].grid(True); axes[0].legend()\n    else:\n        axes[0].set_title(\"Perte (Loss) - Donn√©es insuffisantes\")\n\n    if 'eval_perplexity' in eval_logs.columns:\n        axes[1].plot(eval_logs['epoch'], eval_logs['eval_perplexity'], marker='o', color='green', label=\"Validation Perplexity\")\n        axes[1].set_title(\"Perplexit√© sur l'ensemble de validation\")\n        axes[1].set_xlabel(\"√âpoque\"); axes[1].set_ylabel(\"Perplexit√© (plus bas = meilleur)\"); axes[1].grid(True); axes[1].legend()\n    else:\n        axes[1].set_title(\"Perplexit√© - Donn√©es non trouv√©es\")\n        axes[1].text(0.5, 0.5, \"'eval_perplexity' non trouv√© dans les logs.\", ha='center', va='center')\n        logger.warning(\"La m√©trique 'eval_perplexity' n'a pas √©t√© trouv√©e, le graphique ne sera pas g√©n√©r√©.\")\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\n    best_metrics = getattr(trainer_mlm.state, 'best_metric', None)\n    if best_metrics:\n        logger.info(f\"Meilleure performance MLM atteinte : Perplexit√© = {best_metrics:.4f}\")\nelse:\n    logger.warning(\"Aucun log d'entra√Ænement n'a √©t√© g√©n√©r√©.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 1.3 : Visualisation des R√©sultats MLM ---\nlogger.info(\"G√©n√©ration du graphique de perte pour la phase MLM...\")\nlog_history_mlm = trainer_mlm.state.log_history\ndf_log_mlm = pd.DataFrame(log_history_mlm)\n\ntrain_loss_df = df_log_mlm[df_log_mlm['loss'].notna()]\neval_loss_df = df_log_mlm[df_log_mlm['eval_loss'].notna()]\n\nif not train_loss_df.empty and not eval_loss_df.empty:\n    plt.figure(figsize=(12, 6))\n    plt.plot(train_loss_df['epoch'], train_loss_df['loss'], marker='o', linestyle='-', label=\"Training Loss\")\n    plt.plot(eval_loss_df['epoch'], eval_loss_df['eval_loss'], marker='o', linestyle='-', label=\"Validation Loss\")\n    plt.title(\"Perte durant l'entra√Ænement MLM (Phase 1)\")\n    plt.xlabel(\"√âpoque\")\n    plt.ylabel(\"Perte (Loss)\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\nelse:\n    logger.warning(\"Impossible de g√©n√©rer le graphique de perte MLM. Donn√©es de log insuffisantes.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 1.3 (R√©vis√©e) : Clustering Forc√© √† k=2 et √âvaluation avec √âtiquettes R√©elles ---\n\n# Imports n√©cessaires pour cette cellule\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nlogger.info(\"D√©but de l'√©valuation des embeddings par clustering K-Means (k=2) et comparaison avec les √©tiquettes r√©elles.\")\n\n# --- 1. G√©n√©ration des Embeddings 768D pour l'ENSEMBLE du Dataset ---\nlogger.info(\"Chargement du mod√®le et du tokenizer adapt√©s...\")\n# Assurez-vous que ADAPTED_LM_DIR et df sont d√©finis dans les cellules pr√©c√©dentes\nmodel = AutoModel.from_pretrained(ADAPTED_LM_DIR)\ntokenizer = AutoTokenizer.from_pretrained(ADAPTED_LM_DIR)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\nmodel.eval()\n\nsentences = df['message'].tolist()\n# R√©cup√©rer les √©tiquettes r√©elles pour l'√©valuation finale\ntrue_labels = df['vote_final'].values \n\nbatch_size = 32\nall_embeddings = []\n\nlogger.info(f\"G√©n√©ration des embeddings pour {len(sentences)} phrases...\")\nfor i in tqdm(range(0, len(sentences), batch_size), desc=\"Generating Embeddings (768D)\"):\n    batch_sentences = sentences[i:i+batch_size]\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n        attention_mask = inputs['attention_mask']\n        mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(outputs.last_hidden_state * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        batch_embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n        all_embeddings.append(batch_embeddings)\n\nembeddings_full_768d = np.concatenate(all_embeddings, axis=0)\nlogger.info(\"Normalisation des embeddings 768D...\")\nscaled_embeddings_full_768d = StandardScaler().fit_transform(embeddings_full_768d)\n\n\n# --- 2. Clustering avec Mini-Batch K-Means (k=2) sur les Donn√©es 768D ---\nn_clusters = 2\nlogger.info(f\"Application de l'algorithme Mini-Batch K-Means pour trouver exactement {n_clusters} clusters...\")\nkmeans = MiniBatchKMeans(\n    n_clusters=n_clusters,\n    random_state=42,\n    n_init='auto',\n    batch_size=256\n)\npredicted_clusters = kmeans.fit_predict(scaled_embeddings_full_768d)\n\n\n# --- 3. R√©duction de Dimensionnalit√© avec t-SNE (pour la visualisation) ---\nlogger.info(\"R√©duction de la dimensionnalit√© de 768D √† 2D avec t-SNE (peut prendre du temps)...\")\ntsne = TSNE(\n    n_components=2, \n    perplexity=30, \n    metric='cosine', \n    random_state=42,\n    n_jobs=-1\n)\nembeddings_2d_for_viz = tsne.fit_transform(embeddings_full_768d)\n\n\n# --- 4. √âvaluation du Clustering en Comparaison avec les √âtiquettes R√©elles ---\nprint(\"\\n\" + \"=\"*60)\nprint(\"--- R√âSULTATS DU CLUSTERING K-MEANS (k=2) vs √âTIQUETTES R√âELLES ---\")\n\n# a) M√©trique interne (qualit√© des clusters form√©s)\nsilhouette_avg = silhouette_score(scaled_embeddings_full_768d, predicted_clusters)\nprint(f\"Score de Silhouette (qualit√© intrins√®que des clusters) : {silhouette_avg:.4f}\")\n\n# b) M√©triques externes (comparaison avec les √©tiquettes r√©elles)\nari_score = adjusted_rand_score(true_labels, predicted_clusters)\nnmi_score = normalized_mutual_info_score(true_labels, predicted_clusters)\nprint(f\"Adjusted Rand Score (ARI) : {ari_score:.4f}\")\nprint(f\"Normalized Mutual Information (NMI) : {nmi_score:.4f}\")\nprint(\"\\n(Pour ARI et NMI, 1.0 = correspondance parfaite entre clusters et √©tiquettes, 0.0 = aucune correspondance)\")\nprint(\"=\"*60 + \"\\n\")\n\n\n# --- 5. Visualisation Comparative ---\nlogger.info(\"G√©n√©ration de la visualisation comparative des clusters...\")\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\nfig.suptitle(\"Comparaison entre √âtiquettes R√©elles et Clusters K-Means (k=2)\", fontsize=20)\n\n# Graphique 1 : Coloration par √âTIQUETTES R√âELLES\nsns.scatterplot(\n    x=embeddings_2d_for_viz[:, 0], \n    y=embeddings_2d_for_viz[:, 1],\n    hue=true_labels, # <-- Utilise les vraies √©tiquettes\n    palette=\"viridis\", \n    s=10, alpha=0.7, ax=ax1, legend='full'\n)\nax1.set_title(\"1. Visualisation selon les √âtiquettes R√©elles\", fontsize=16)\nax1.set_xlabel(\"Composante t-SNE 1\")\nax1.set_ylabel(\"Composante t-SNE 2\")\nax1.grid(True, linestyle='--', alpha=0.6)\n\n# Graphique 2 : Coloration par CLUSTERS PR√âDITS\nsns.scatterplot(\n    x=embeddings_2d_for_viz[:, 0], \n    y=embeddings_2d_for_viz[:, 1],\n    hue=predicted_clusters, # <-- Utilise les 2 clusters trouv√©s par K-Means\n    palette=\"plasma\", \n    s=10, alpha=0.7, ax=ax2, legend='full'\n)\nax2.set_title(\"2. Visualisation selon les 2 Clusters Pr√©dits\", fontsize=16)\nax2.set_xlabel(\"Composante t-SNE 1\")\nax2.set_ylabel(\"Composante t-SNE 2\")\nax2.grid(True, linestyle='--', alpha=0.6)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 2 : Fine-Tuning pour la Classification\n\nMaintenant que notre mod√®le comprend notre vocabulaire sp√©cifique, nous allons l'entra√Æner √† la t√¢che finale : classifier les messages comme \"hateful\" ou \"not_hateful\".\n\n### √âtape 2.1 : Pr√©paration des donn√©es\n\nNous devons pr√©parer les donn√©es en associant chaque message √† son √©tiquette num√©rique, puis en les divisant en ensembles d'entra√Ænement et de test.","metadata":{}},{"cell_type":"code","source":"# --- √âTAPE DE NETTOYAGE : Lib√©rer l'espace disque ---\nimport shutil\nimport os\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nmlm_results_dir = \"/kaggle/working/mlm_results\"\n\nif os.path.exists(mlm_results_dir):\n    logger.info(f\"Nettoyage de l'espace disque en supprimant les checkpoints MLM interm√©diaires de '{mlm_results_dir}'...\")\n    try:\n        shutil.rmtree(mlm_results_dir)\n        logger.info(\"Nettoyage termin√© avec succ√®s.\")\n    except OSError as e:\n        logger.error(f\"Erreur lors de la suppression du dossier {mlm_results_dir}: {e}\")\n        # Alternative plus forc√©e si la premi√®re √©choue\n        !rm -rf {mlm_results_dir}\nelse:\n    logger.info(\"Le dossier des r√©sultats MLM n'existe pas, pas de nettoyage n√©cessaire.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 2.1 : Pr√©paration et Tokenization des Donn√©es de Classification ---\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\n\nlogger.info(\"Phase 2 : Pr√©paration des donn√©es pour la Classification.\")\n\n# --- Mappage des Labels ---\ndf['vote_final'] = df['vote_final'].astype(str)\nlabels_list = sorted(df['vote_final'].unique())\nlabel2id = {label: i for i, label in enumerate(labels_list)}\nid2label = {i: label for label, i in label2id.items()}\ndf['labels'] = df['vote_final'].map(label2id)\nlogger.info(f\"Mappage des labels cr√©√© : {label2id}\")\n\n# --- Division en Train / Validation / Test ---\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['labels'])\nlogger.info(f\"Taille des ensembles - Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n\n# --- R√©√©quilibrage par Sursampling (Oversampling) ---\nlogger.info(\"R√©√©quilibrage de l'ensemble d'entra√Ænement...\")\ntry:\n    if len(train_df['labels'].value_counts()) > 1:\n        majority_class_id = train_df['labels'].value_counts().idxmax()\n        df_majority = train_df[train_df.labels == majority_class_id]\n        df_minority = train_df[train_df.labels != majority_class_id]\n        df_minority_oversampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n        train_df_balanced = pd.concat([df_majority, df_minority_oversampled])\n        logger.info(f\"Distribution apr√®s r√©√©quilibrage:\\n{train_df_balanced['vote_final'].value_counts()}\")\n    else:\n        logger.warning(\"Une seule classe d√©tect√©e dans le jeu d'entra√Ænement, pas de r√©√©quilibrage effectu√©.\")\n        train_df_balanced = train_df\nexcept Exception as e:\n    logger.error(f\"Erreur pendant le r√©√©quilibrage : {e}. Utilisation du jeu de donn√©es original.\")\n    train_df_balanced = train_df\n\n# --- Cr√©ation des Datasets Hugging Face ---\ntrain_dataset = Dataset.from_pandas(train_df_balanced)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n# --- Tokenization ---\nlogger.info(f\"Chargement du tokenizer adapt√© depuis {ADAPTED_LM_DIR}...\")\nclassifier_tokenizer = AutoTokenizer.from_pretrained(ADAPTED_LM_DIR)\n\ndef tokenize_function_classifier(examples):\n    return classifier_tokenizer(examples['message'], truncation=True, padding='max_length', max_length=128)\n\ncolumns_to_remove = ['message', 'vote_final'] # On garde 'labels' !\ntrain_tokenized = train_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\nval_tokenized = val_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\ntest_tokenized = test_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\n\nlogger.info(\"Pr√©paration des donn√©es de classification termin√©e.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### √âtape 2.2 : Entra√Ænement du Classifieur\n\nNous chargeons le mod√®le que nous avons adapt√© en Phase 1. Il conna√Æt d√©j√† notre vocabulaire. Nous le chargeons maintenant avec une t√™te de classification (`AutoModelForSequenceClassification`) et nous le fine-tunons sur nos donn√©es √©tiquet√©es.","metadata":{}},{"cell_type":"code","source":"# --- √âtape 2.2 : Pr√©paration du Mod√®le de Classification (Cong√©lation) ---\nfrom transformers import AutoModelForSequenceClassification\n\nlogger.info(f\"Chargement du mod√®le adapt√© depuis : {ADAPTED_LM_DIR}\")\nclassifier_model = AutoModelForSequenceClassification.from_pretrained(\n    ADAPTED_LM_DIR,\n    num_labels=len(label2id),\n    id2label=id2label,\n    label2id=label2id\n)\n\n# --- CORRECTION PRINCIPALE : Utiliser 'roberta' au lieu de 'distilbert' ---\n# Le mod√®le de base pour CamemBERT s'appelle 'roberta' en interne.\nlogger.info(\"Cong√©lation du corps du Transformer pour le fine-tuning initial...\")\n\n# On g√®le toutes les couches du corps du mod√®le\nfor param in classifier_model.roberta.parameters():\n    param.requires_grad = False\n\n# MAIS, on s'assure que la couche d'embedding reste entra√Ænable pour qu'elle continue de s'adapter.\n# Les embeddings font partie de 'roberta', donc on acc√®de via `roberta.embeddings`\nfor param in classifier_model.roberta.embeddings.parameters():\n    param.requires_grad = True\n\n# La t√™te de classification (classifier_model.classifier) est automatiquement\n# entra√Ænable car elle est nouvelle et ses param√®tres ont `requires_grad=True` par d√©faut.\n\n# --- V√©rification (inchang√©e) ---\ntrainable_params = sum(p.numel() for p in classifier_model.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in classifier_model.parameters())\nlogger.info(f\"Param√®tres entra√Ænables (phase 1) : {trainable_params} / {total_params} ({100 * trainable_params / total_params:.2f}%)\")\n# Le log devrait maintenant s'afficher correctement, montrant que seul un petit pourcentage\n# des poids est pr√™t √† √™tre entra√Æn√©.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Le code ci-dessous est CORRECT et fonctionnera apr√®s la mise √† jour de l'environnement.\n\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score\nfrom transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n\n# ASSUREZ-VOUS QUE `label2id` EST DISPONIBLE ET CONTIENT BIEN LE MAPPING\nhateful_class_id = label2id.get('hateful')\nif hateful_class_id is None:\n    hateful_class_id = 1\n    logger.warning(f\"Label 'hateful' non trouv√© dans label2id. Utilisation de l'ID {hateful_class_id} comme classe positive par d√©faut.\")\n\n# Fonction de calcul des m√©triques, maintenant centr√©e sur le rappel\ndef compute_metrics_cls(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    recall_hateful = recall_score(labels, predictions, pos_label=hateful_class_id, zero_division=0)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1\": f1_score(labels, predictions, average='weighted', zero_division=0),\n        \"recall_hateful\": recall_hateful\n    }\n\n# Arguments d'entra√Ænement avec Early Stopping bas√© sur le RAPPEL\ntraining_args_phase1 = TrainingArguments(\n    output_dir=\"/kaggle/working/classifier_results_phase1\",\n    num_train_epochs=15,\n    learning_rate=5e-4,\n    per_device_train_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,\n    fp16=True,\n    \n    # Ces arguments sont maintenant reconnus par la nouvelle version de la biblioth√®que\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    \n    load_best_model_at_end=True, \n    metric_for_best_model=\"recall_hateful\",\n    greater_is_better=True,\n    \n    report_to=\"none\"\n)\n\n# Cr√©ation du Trainer\ntrainer_phase1 = Trainer(\n    model=classifier_model,\n    args=training_args_phase1,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=classifier_tokenizer,\n    compute_metrics=compute_metrics_cls,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\nlogger.info(\"D√©but de la phase 1 de fine-tuning (optimisation du rappel)...\")\ntrainer_phase1.train()\n\nlogger.info(\"Phase 1 de fine-tuning (rappel) termin√©e.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- √âtape 2.4 : D√©cong√©lation et Fine-Tuning Final (Mod√®le Complet, optimis√© pour le Rappel) ---\nlogger.info(\"D√©cong√©lation de toutes les couches pour le fine-tuning final...\")\nfor param in classifier_model.parameters():\n    param.requires_grad = True\nlogger.info(\"Tous les param√®tres sont maintenant entra√Ænables.\")\n\n# Arguments pour le fine-tuning final avec un learning rate tr√®s bas\ntraining_args_final = TrainingArguments(\n    output_dir=\"/kaggle/working/classifier_results_final\",\n    num_train_epochs=10, # Limite maximale d'√©poques\n    \n    # Taux d'apprentissage tr√®s bas pour un affinage de pr√©cision\n    learning_rate=2e-5, \n    \n    per_device_train_batch_size=BATCH_SIZE, # Assurez-vous que BATCH_SIZE est d√©fini\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,\n    fp16=True,\n    \n    # M√™mes strat√©gies que pr√©c√©demment\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    report_to=\"none\",\n    \n    # --- CHANGEMENT PRINCIPAL ICI ---\n    load_best_model_at_end=True,\n    metric_for_best_model=\"recall_hateful\", # On continue de surveiller le rappel\n    greater_is_better=True\n)\n\n# On cr√©e un nouveau Trainer pour cette phase finale.\n# Il utilise la m√™me fonction `compute_metrics_cls` que pr√©c√©demment.\ntrainer_final = Trainer(\n    model=classifier_model, # Le mod√®le a maintenant toutes ses couches d√©gel√©es\n    args=training_args_final,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=classifier_tokenizer,\n    compute_metrics=compute_metrics_cls,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] # Patience plus courte pour la phase d'affinage\n)\n\nlogger.info(\"D√©but du fine-tuning final (mod√®le complet, optimisation du rappel)...\")\ntrainer_final.train()\n\n# --- SAUVEGARDE DU MOD√àLE FINAL ---\n# `trainer_final.model` contient maintenant la meilleure version du mod√®le complet,\n# bas√©e sur le RAPPEL de la classe haineuse.\nlogger.info(f\"Sauvegarde du meilleur mod√®le final (optimis√© pour le rappel) dans : {FINAL_CLASSIFIER_DIR}\")\ntrainer_final.save_model(FINAL_CLASSIFIER_DIR)\nclassifier_tokenizer.save_pretrained(FINAL_CLASSIFIER_DIR)\n\nlogger.info(\"Phase 2 (Fine-tuning de classification) termin√©e avec succ√®s.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### √âtape 2.3 : √âvaluation, Visualisation et Sauvegarde du Mod√®le Final\n\nL'entra√Ænement est termin√©. Il est temps d'analyser en d√©tail les performances de notre mod√®le fine-tun√©. Nous allons :\n1.  Sauvegarder le meilleur mod√®le et son tokenizer.\n2.  Visualiser les courbes d'apprentissage pour confirmer que l'entra√Ænement s'est bien d√©roul√©.\n3.  Calculer les m√©triques de performance (pr√©cision, rappel, F1-score).\n4.  Afficher une matrice de confusion pour comprendre les types d'erreurs que le mod√®le commet.","metadata":{}},{"cell_type":"code","source":"# --- √âtape 2.5 : √âvaluation Finale et Visualisation ---\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nlogger.info(\"√âvaluation finale sur le jeu de test (donn√©es jamais vues)...\")\npredictions_output = trainer_final.predict(test_tokenized)\ny_preds = predictions_output.predictions.argmax(axis=1)\ny_true = test_tokenized['labels']\n\n# Rapport de classification (Pr√©cision, Rappel, F1-Score)\nprint(\"\\n\" + \"=\"*50)\nprint(\"--- Rapport de Classification Final ---\")\ntarget_names_ordered = [id2label[i] for i in sorted(id2label.keys())]\nprint(classification_report(y_true, y_preds, target_names=target_names_ordered))\nprint(\"=\"*50 + \"\\n\")\n\n# Matrice de confusion\ncm = confusion_matrix(y_true, y_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_ordered, yticklabels=target_names_ordered)\nplt.title(\"Matrice de Confusion du Mod√®le Final sur le Jeu de Test\")\nplt.xlabel(\"√âtiquette Pr√©dite\")\nplt.ylabel(\"√âtiquette Vraie\")\nplt.show()\n\n# --- Visualisation des courbes d'entra√Ænement de la derni√®re phase ---\nlog_history_cls = trainer_final.state.log_history\ndf_log_cls = pd.DataFrame(log_history_cls)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\nfig.suptitle(\"Performances du Fine-Tuning Final (Phase 2.4)\", fontsize=16)\n\n# Filtrer les donn√©es pour les graphiques\ntrain_loss_cls = df_log_cls[df_log_cls['loss'].notna()]\neval_loss_cls = df_log_cls[df_log_cls['eval_loss'].notna()]\neval_acc_cls = df_log_cls[df_log_cls['eval_f1'].notna()] # On affiche le F1-score\n\n# Graphique de la Perte\nif not eval_loss_cls.empty:\n    ax1.plot(train_loss_cls['epoch'], train_loss_cls['loss'], marker='o', label=\"Training Loss\")\n    ax1.plot(eval_loss_cls['epoch'], eval_loss_cls['eval_loss'], marker='o', label=\"Validation Loss\")\n    ax1.set_title(\"Perte (Loss)\")\n    ax1.set_xlabel(\"√âpoque\"); ax1.set_ylabel(\"Perte\"); ax1.grid(True); ax1.legend()\n\n# Graphique du F1-score\nif not eval_acc_cls.empty:\n    ax2.plot(eval_acc_cls['epoch'], eval_acc_cls['eval_f1'], marker='o', color='purple', label=\"Validation F1-Score\")\n    ax2.set_title(\"F1-Score\")\n    ax2.set_xlabel(\"√âpoque\"); ax2.set_ylabel(\"F1-Score\"); ax2.grid(True); ax2.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### √âtape 2.4 : Test sur des Exemples Concrets avec une Pipeline\n\nLa m√©thode la plus simple pour utiliser notre mod√®le est de le charger dans une `pipeline` Hugging Face. Cela s'occupe de toute la pr√©-traitement et du post-traitement pour nous.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Charger le mod√®le final dans une pipeline pour un test facile\nlogger.info(\"Chargement de la pipeline avec le mod√®le final...\")\n# S'assurer d'utiliser le GPU s'il est disponible\ndevice = 0 if torch.cuda.is_available() else -1\nfinal_pipe = pipeline(\"text-classification\", model=FINAL_CLASSIFIER_DIR, device=device)\n\n# Exemples de test\ntest_phrases = [\n    \"Je te d√©teste, tu n'es qu'un idiot.\",\n    \"Passe une excellente journ√©e, merci pour ton aide !\",\n    \"Ce nkwada pense qu'il peut nous tromper.\", # Exemple avec vocabulaire sp√©cifique\n    \"C'est une honte pour notre pays.\",\n    \"Arr√™te de dire des b√™tises, tu es nul\",\n    \"tu es deguelasse\",\n    \"c'est pitoyable\",\n]\n\nlogger.info(\"\\n--- Test du mod√®le final sur des exemples concrets ---\")\nfor phrase in test_phrases:\n    result = final_pipe(phrase)\n    print(f\"Phrase: '{phrase}'\\nPr√©diction: {result}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# S'assurer que la pipeline est bien charg√©e\ntry:\n    final_pipe\nexcept NameError:\n    from transformers import pipeline\n    logger.info(\"Rechargement de la pipeline pour l'interface interactive...\")\n    device = 0 if torch.cuda.is_available() else -1\n    final_pipe = pipeline(\"text-classification\", model=FINAL_CLASSIFIER_DIR, device=device)\n\ndef classify_interactive():\n    \"\"\"Lance une boucle de classification interactive.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"      Interface de Classification de Discours Haineux\")\n    print(\"=\"*60)\n    print(\"Entrez une phrase √† analyser. Tapez 'quitter' pour arr√™ter.\")\n    print(\"-\" * 60)\n\n    while True:\n        # Demander une phrase √† l'utilisateur\n        user_input = input(\"Votre phrase > \")\n\n        # Condition de sortie\n        if user_input.lower() == 'quitter':\n            print(\"Au revoir !\")\n            break\n        \n        # V√©rifier que l'input n'est pas vide\n        if not user_input.strip():\n            print(\"Veuillez entrer une phrase non vide.\")\n            continue\n\n        # Faire la pr√©diction avec la pipeline\n        result = final_pipe(user_input)[0] # On prend le premier √©l√©ment de la liste\n        label = result['label']\n        score = result['score']\n\n        # Afficher le r√©sultat de mani√®re lisible\n        print(f\"  -> Pr√©diction : '{label}' (Confiance : {score:.2%})\")\n        print(\"-\" * 60)\n\n# Lancer l'interface interactive\nclassify_interactive()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}