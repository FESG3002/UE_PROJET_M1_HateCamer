{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12259712,"sourceType":"datasetVersion","datasetId":7725383}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Modele de classification des messages haineux et non haineux dans le contexte Camerounais\n\n### TCHIAZE FOUOSSO ROMERO\n### NDONKOU FRANCK\n### ENGOULOU GAETAN","metadata":{}},{"cell_type":"code","source":"\n# --- Étape 0 : Installation des Dépendances Compatibles et Redémarrage ---\n# Exécutez cette cellule UNE SEULE FOIS au début de votre session.\n# Elle va forcer le redémarrage du noyau, ce qui est NORMAL.\n# Après le redémarrage, ne la ré-exécutez pas et passez à la cellule suivante.\nimport os\n\nprint(\"Installation des versions de bibliothèques compatibles pour un entraînement stable...\")\n# On utilise un ensemble de versions connues pour bien fonctionner ensemble.\n# `transformers==4.41.2` est une version stable qui fonctionne bien avec `peft` récent.\n!pip install transformers==4.41.2 datasets==2.19.1 sentencepiece==0.2.0 accelerate==0.30.1 peft==0.10.0 scikit-learn seaborn -q\nprint(\"Installation terminée.\")\n\nprint(\"\\nREDÉMARRAGE DU KERNEL pour appliquer les changements et nettoyer l'état du GPU...\")\nprint(\"C'est normal. Ne ré-exécutez pas cette cellule après le redémarrage.\")\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model page: https://huggingface.co/Poulpidot/distilcamenbert-french-hate-speech\n\n⚠️ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/Poulpidot/distilcamenbert-french-hate-speech)\n\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) 🙏","metadata":{}},{"cell_type":"markdown","source":"# Projet de Détection de Discours Haineux : Fine-Tuning Avancé\n\n**Objectif :** Adapter le modèle `Poulpidot/distilcamenbert-french-hate-speech` à un corpus de textes spécifiques (contenant du vocabulaire camerounais) pour améliorer la performance de classification.\n\n**Démarche en 2 phases :**\n1.  **Phase 1 : Adaptation au Domaine (MLM)**\n    - Entraînement d'un nouveau tokenizer sur notre corpus.\n    - Fine-tuning du modèle pré-entraîné via le *Masked Language Modeling* (MLM) pour qu'il apprenne notre vocabulaire.\n2.  **Phase 2 : Fine-tuning pour la Classification**\n    - Utilisation du modèle adapté en Phase 1 comme base.\n    - Fine-tuning sur la tâche de classification binaire (hateful / not_hateful).\n\n**Résultats attendus :** Un modèle de classification robuste, des visualisations de performance (perte, précision) et une matrice de confusion pour l'évaluation finale.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport logging\n\n# Configurer le logging pour plus de verbosité\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Étape 1 : Installer les dépendances nécessaires\ntry:\n    from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n    logger.info(\"Transformers déjà installé.\")\nexcept ImportError:\n    logger.info(\"Installation de transformers et dépendances...\")\n    try:\n        !pip install transformers==4.45.2 torch sentencepiece\n        from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n        logger.info(\"Transformers installé avec succès.\")\n    except Exception as e:\n        logger.error(f\"Erreur lors de l'installation de transformers : {e}\")\n        raise\n\n# Définir le nom du modèle\nmodel_name = \"Poulpidot/distilcamenbert-french-hate-speech\"\n\n# Définir le dossier de sauvegarde (dans /kaggle/working/ pour Kaggle)\noutput_dir = \"/kaggle/working/distilcamenbert_french_hate_speech\"\nos.makedirs(output_dir, exist_ok=True)\nlogger.info(f\"Dossier de sauvegarde créé ou existant : {output_dir}\")\n\n# Étape 2 : Vérifier si le modèle existe déjà localement\nrequired_files = ['config.json', 'model.safetensors', 'sentencepiece.bpe.model', 'tokenizer.json', 'tokenizer_config.json', 'special_tokens_map.json']\nmodel_exists_locally = all(os.path.exists(os.path.join(output_dir, f)) for f in required_files)\n\nif not model_exists_locally:\n    try:\n        # Télécharger et sauvegarder le tokenizer\n        logger.info(f\"Téléchargement du tokenizer depuis {model_name}...\")\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        tokenizer.save_pretrained(output_dir)\n        logger.info(\"Tokenizer sauvegardé.\")\n\n        # Télécharger et sauvegarder le modèle\n        logger.info(f\"Téléchargement du modèle depuis {model_name}...\")\n        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        model.save_pretrained(output_dir)\n        logger.info(\"Modèle sauvegardé.\")\n    except Exception as e:\n        logger.error(f\"Erreur lors du téléchargement ou de la sauvegarde : {e}\")\n        raise\nelse:\n    logger.info(f\"Modèle déjà présent dans {output_dir}. Chargement local.\")\n\n# Vérifier que les fichiers sont bien sauvegardés\nprint(\"Modèle et tokenizer sauvegardés dans :\", output_dir)\nprint(\"Fichiers présents :\", os.listdir(output_dir))\n\n# Étape 3 : Tester le modèle localement avec une phrase\ntry:\n    # Charger la pipeline depuis le dossier local\n    logger.info(f\"Chargement de la pipeline depuis {output_dir}...\")\n    pipe = pipeline(\"text-classification\", model=output_dir, tokenizer=output_dir, device=0 if torch.cuda.is_available() else -1)\n\n    # Phrase à tester\n    phrase = \"Cette personne est vraiment méchante et inutile.\"\n\n    # Faire une prédiction\n    result = pipe(phrase)\n\n    # Afficher le résultat\n    print(f\"Phrase : {phrase}\")\n    print(f\"Prédiction : {result}\")\nexcept Exception as e:\n    logger.error(f\"Erreur lors de l'utilisation de la pipeline : {e}\")\n    raise\n\n# Étape 4 : Tester avec le tokenizer et le modèle directement\ntry:\n    # Charger le tokenizer et le modèle localement\n    tokenizer = AutoTokenizer.from_pretrained(output_dir)\n    model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n\n    # Tokeniser la phrase\n    inputs = tokenizer(phrase, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=100)\n\n    # Évaluer le modèle\n    model.eval()\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probs = torch.softmax(logits, dim=-1)\n        label_idx = torch.argmax(probs, dim=-1).item()\n        labels = {0: \"not_hateful\", 1: \"hateful\"}  # Labels confirmés pour le modèle\n\n    print(f\"Prédiction détaillée : {labels[label_idx]} (probabilité : {probs[0][label_idx]:.4f})\")\nexcept Exception as e:\n    logger.error(f\"Erreur lors du test manuel : {e}\")\n    raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"import os\nimport shutil\n\n# Chemin du dossier à compresser\nfolder_path = \"/kaggle/working/distilcamenbert_french_hate_speech\"\n\n# Nom du fichier ZIP à créer\nzip_file_name = \"distilcamenbert_french_hate_speech.zip\"\n\n# Compresser le dossier en ZIP\nshutil.make_archive(zip_file_name[:-4], 'zip', folder_path)\n\n# Vérifier que le fichier ZIP a été créé\nprint(\"Fichier ZIP créé :\", os.path.join(\"/kaggle/working\", zip_file_name))\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport numpy as np\nimport os\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy\n\n# --- GESTION DE L'INSTALLATION (si nécessaire) ---\n# Si le modèle n'est pas trouvé, le code suivant tentera de l'installer.\ntry:\n    nlp = spacy.load(\"fr_core_news_sm\")\n    print(\"Modèle SpaCy 'fr_core_news_sm' chargé avec succès.\")\nexcept OSError:\n    print(\"Modèle SpaCy 'fr_core_news_sm' non trouvé. Tentative de téléchargement...\")\n    try:\n        spacy.cli.download(\"fr_core_news_sm\")\n        nlp = spacy.load(\"fr_core_news_sm\")\n        print(\"Modèle téléchargé et chargé avec succès.\")\n    except Exception as e:\n        print(f\"Échec du téléchargement automatique du modèle SpaCy : {e}\")\n        exit()\n\n# Télécharger les stop words pour le français\nnltk.download('stopwords', quiet=True)\nfrench_stopwords = set(stopwords.words('french'))\n\n\n# --- CHEMINS DES FICHIERS ---\ninput_file = \"/kaggle/input/datacamer/dataMessages_filtered\"\noutput_file = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"\n\n# Vérifier si le fichier d'entrée existe\nif not os.path.exists(input_file):\n    print(f\"Erreur : Le fichier {input_file} n'a pas été trouvé.\")\n    # Si le chemin est incorrect, cette ligne aide à trouver le bon.\n    # print(\"Vérifiez le contenu de /kaggle/input/ :\", os.listdir(\"/kaggle/input/\"))\n    exit()\n\n\n# --- NOUVELLES FONCTIONS DE PRÉTRAITEMENT ---\n# Ces fonctions sont ajoutées sans modifier les vôtres.\n\ndef normalize_repeated_chars(text):\n    \"\"\"Normalise les caractères répétés plus de deux fois. Ex: 'troooop' -> 'troop'.\"\"\"\n    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n\ndef lemmatize_text_spacy(text):\n    \"\"\"\n    Effectue la lemmatisation en utilisant SpaCy.\n    C'est une étape plus avancée que la simple suppression de stopwords.\n    Ex: \"les voitures roulaient vite\" -> \"le voiture rouler vite\"\n    \"\"\"\n    # On désactive le parser et la reconnaissance d'entités pour la vitesse.\n    doc = nlp(text, disable=['parser', 'ner'])\n    return \" \".join([token.lemma_ for token in doc])\n\n\n# --- VOS FONCTIONS DE PRÉTRAITEMENT (INCHANGÉES) ---\n\ndef remove_entity(raw_text):\n    entity_regex = r\"&[^\\s;]+;\"\n    return re.sub(entity_regex, \"\", raw_text)\n\ndef change_user(raw_text):\n    regex = r\"@([^ ]+)\"\n    return re.sub(regex, \"user\", raw_text)\n\ndef remove_url(raw_text):\n    url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n    return re.sub(url_regex, '', raw_text)\n\ndef remove_noise_symbols(raw_text):\n    return raw_text.replace('\"', '').replace(\"'\", '').replace(\"!\", '').replace(\"`\", '').replace(\"..\", '')\n\ndef remove_punctuation(text):\n    return \"\".join(c for c in text if c not in string.punctuation)\n\ndef remove_stopwords(text):\n    words = text.split()\n    return ' '.join([word for word in words if word.lower() not in french_stopwords])\n\ndef remove_names(text):\n    try:\n        doc = nlp(text)\n        return ' '.join([token.text for token in doc if token.ent_type_ not in ('PER', 'LOC', 'ORG')])\n    except Exception as e:\n        print(f\"Erreur dans remove_names : {e}\")\n        return text\n\n\n# --- PIPELINE DE PRÉTRAITEMENT INTÉGRANT LES NOUVELLES ÉTAPES ---\n\ndef preprocess_text(text):\n    \"\"\"\n    Applique toutes les étapes de prétraitement, anciennes et nouvelles,\n    dans un ordre logique et optimisé.\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    \n    # 1. Nettoyage initial (URLs, mentions, entités)\n    text = remove_url(text)\n    text = change_user(text)\n    text = remove_entity(text)\n    \n    # 2. Normalisation du texte\n    text = text.lower()  # Mise en minuscule\n    text = normalize_repeated_chars(text) # NOUVELLE ÉTAPE\n    \n    # 3. Lemmatisation (gère les formes de mots)\n    # text = lemmatize_text_spacy(text) # NOUVELLE ÉTAPE (Optionnelle, puissante mais lente)\n    # NOTE: La lemmatisation est très puissante mais peut être lente.\n    # Pour commencer, je la laisse commentée. Décommentez-la pour un nettoyage plus profond.\n\n    # 4. Suppression du bruit (symboles, ponctuation)\n    text = remove_noise_symbols(text)\n    text = remove_punctuation(text)\n    \n    # 5. Suppression des mots non pertinents (stopwords, noms)\n    text = remove_stopwords(text)\n    text = remove_names(text)\n    \n    # 6. Nettoyage final des espaces\n    text = ' '.join(text.split())\n    \n    return text\n\n\n# --- FONCTION DE STATISTIQUES (INCHANGÉE) ---\n\ndef compute_statistics(df, text_column, label_column, title_prefix=\"\"):\n    print(f\"\\n=== {title_prefix} Statistiques ===\")\n    print(f\"Nombre total d'exemples : {len(df)}\")\n    \n    class_counts = df[label_column].value_counts()\n    print(\"\\nDistribution des classes :\"); print(class_counts)\n    \n    df['word_count'] = df[text_column].apply(lambda x: len(str(x).split()))\n    print(\"\\nStatistiques sur la longueur des phrases (en mots) :\"); print(df['word_count'].describe())\n    \n    all_words = ' '.join(df[text_column].astype(str)).split()\n    word_freq = Counter(all_words).most_common(10)\n    print(\"\\n10 mots les plus fréquents :\"); print(word_freq)\n    \n    plt.figure(figsize=(15, 10))\n    plt.subplot(2, 2, 1)\n    sns.countplot(x=label_column, data=df); plt.title(f\"{title_prefix} Distribution des classes\")\n    \n    plt.subplot(2, 2, 2)\n    plt.hist(df['word_count'], bins=20, edgecolor='black'); plt.title(f\"{title_prefix} Histogramme de la longueur des phrases\")\n    \n    plt.subplot(2, 2, 3)\n    words, freqs = zip(*word_freq)\n    sns.barplot(x=list(freqs), y=list(words)); plt.title(f\"{title_prefix} 10 mots les plus fréquents\")\n    \n    plt.tight_layout()\n    plt.savefig(f\"/kaggle/working/statistics_{title_prefix.lower().replace(' ', '_')}.png\")\n    plt.show()\n    \n    df.drop(columns=['word_count'], inplace=True, errors='ignore')\n    return df\n\n\n# --- EXÉCUTION DU SCRIPT ---\n\ntry:\n    df = pd.read_csv(input_file, encoding='utf-8')\nexcept Exception as e:\n    print(f\"Erreur lors de la lecture du fichier {input_file} : {e}\")\n    exit()\n\nif not all(col in df.columns for col in ['message', 'vote_final']):\n    print(\"Erreur : Le fichier CSV doit contenir les colonnes 'message' et 'vote_final'.\")\n    exit()\n\n# Étape 1 : Étude statistique avant prétraitement\ndf = compute_statistics(df, text_column='message', label_column='vote_final', title_prefix=\"Avant prétraitement\")\n\n# Étape 2 : Prétraitement des phrases\nprint(\"\\nApplication du prétraitement sur les messages...\")\nfrom tqdm.auto import tqdm\ntqdm.pandas() # Active la barre de progression pour .apply()\ndf['message_cleaned'] = df['message'].progress_apply(preprocess_text)\nprint(\"Prétraitement terminé.\")\n\n# Étape 3 : Étude statistique après prétraitement\ndf = compute_statistics(df, text_column='message_cleaned', label_column='vote_final', title_prefix=\"Après prétraitement\")\n\n# Étape 4 : Sauvegarder le fichier CSV prétraité\ntry:\n    output_df = df[['message_cleaned', 'vote_final']].rename(columns={'message_cleaned': 'message'})\n    output_df.to_csv(output_file, index=False, encoding='utf-8')\n    print(f\"\\nFichier CSV prétraité sauvegardé : {output_file}\")\n    print(\"Aperçu des premières lignes :\")\n    print(output_df.head())\nexcept Exception as e:\n    print(f\"Erreur lors de la sauvegarde du fichier {output_file} : {e}\")\n    exit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définir les chemins des fichiers\ninput_file = \"/kaggle/input/datacamer/dataMessages_filtered\"  # Chemin du fichier d'entrée\noutput_file = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"  # Chemin de sortie\n\n# Charger le fichier CSV\ntry:\n    df = pd.read_csv(input_file, encoding='utf-8')\nexcept Exception as e:\n    print(f\"Erreur lors de la lecture du fichier {input_file} : {e}\")\n    exit()\n\n# Vérifier la structure du fichier\nif not all(col in df.columns for col in ['message', 'vote_final']):\n    print(\"Erreur : Le fichier CSV doit contenir les colonnes 'message' et 'vote_final'.\")\n    exit()\n\n# Étape 1 : Étude statistique avant prétraitement\ndf = compute_statistics(df, text_column='message', label_column='vote_final', title_prefix=\"Avant prétraitement\")\n\n# Étape 2 : Prétraitement des phrases\ndf['message_cleaned'] = df['message'].apply(preprocess_text)\n\n# Étape 3 : Étude statistique après prétraitement\ndf = compute_statistics(df, text_column='message_cleaned', label_column='vote_final', title_prefix=\"Après prétraitement\")\n\n# Étape 4 : Sauvegarder le fichier CSV prétraité\ntry:\n    output_df = df[['message_cleaned', 'vote_final']].rename(columns={'message_cleaned': 'message'})\n    output_df.to_csv(output_file, index=False, encoding='utf-8')\n    print(f\"\\nFichier CSV prétraité sauvegardé : {output_file}\")\n    print(\"Aperçu des premières lignes :\")\n    print(output_df.head())\nexcept Exception as e:\n    print(f\"Erreur lors de la sauvegarde du fichier {output_file} : {e}\")\n    exit()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cellule 2 : Imports et Configuration (APRÈS REDÉMARRAGE)\n\nimport os\nimport pandas as pd\nimport torch\nimport logging\nfrom tqdm.auto import tqdm\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom transformers import (\n    AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer, DataCollatorForLanguageModeling,\n    EarlyStoppingCallback\n)\nfrom transformers.trainer_callback import TrainerCallback\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Configuration\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# --- Définition des Chemins et Paramètres ---\nBASE_MODEL_DIR = \"/kaggle/working/distilcamenbert_french_hate_speech\"\nDATASET_PATH = \"/kaggle/working/FirstDataSet_Whatsapp_Youtube_processed_final.csv\"\nEXTENDED_MODEL_DIR = \"/kaggle/working/distilcamembert_extended\"\nADAPTED_LM_DIR = \"/kaggle/working/distilcamembert_extended_adapted_lm\"\nFINAL_CLASSIFIER_DIR = \"/kaggle/working/final_hate_speech_classifier\"\nMLM_EPOCHS = 15 # Élevé, car Early Stopping décidera\nCLASSIFICATION_EPOCHS = 20 # Élevé, car Early Stopping décidera\nBATCH_SIZE = 16\nLEARNING_RATE = 5e-6 # Taux d'apprentissage faible et stable\n\nlogger.info(\"Configuration et imports terminés.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 1.1 : Extension du Tokenizer et du Modèle ---\nlogger.info(\"Phase 1 : Adaptation du modèle au langage spécifique.\")\n\nlogger.info(\"Chargement du dataset et du tokenizer original...\")\ndf = pd.read_csv(DATASET_PATH).dropna(subset=['message', 'vote_final'])\ndf['message'] = df['message'].astype(str)\noriginal_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_DIR)\noriginal_vocab = set(original_tokenizer.get_vocab().keys())\n\nlogger.info(\"Identification des mots absents du vocabulaire original...\")\ndef extract_words(text): return set(re.findall(r\"[\\w']+\", text.lower()))\ncorpus_words = set()\nfor text in tqdm(df['message'], desc=\"Analyse du corpus\"): corpus_words.update(extract_words(text))\nnew_tokens = list(corpus_words - original_vocab)\nword_counts = pd.Series(' '.join(df['message'].str.lower()).split()).value_counts()\nnew_tokens_to_add = [token for token in new_tokens if word_counts.get(token, 0) > 1]\n\nlogger.info(f\"Ajout de {len(new_tokens_to_add)} nouveaux mots pertinents au tokenizer.\")\noriginal_tokenizer.add_tokens(new_tokens_to_add)\n\nlogger.info(\"Chargement et redimensionnement du modèle de base...\")\nmodel_for_extension = AutoModelForMaskedLM.from_pretrained(BASE_MODEL_DIR)\nmodel_for_extension.resize_token_embeddings(len(original_tokenizer))\n\nlogger.info(f\"Sauvegarde du couple modèle/tokenizer étendu dans {EXTENDED_MODEL_DIR}...\")\nos.makedirs(EXTENDED_MODEL_DIR, exist_ok=True)\nmodel_for_extension.save_pretrained(EXTENDED_MODEL_DIR)\noriginal_tokenizer.save_pretrained(EXTENDED_MODEL_DIR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 1.2 : Fine-tuning MLM avec Stabilisation, Métriques et Compatibilité Maximale ---\n\n# Imports nécessaires pour cette cellule\nimport torch\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom transformers import (\n    TrainerCallback, EarlyStoppingCallback, Trainer, TrainingArguments, \n    __version__ as transformers_version  # Import pour détecter la version\n)\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nfrom packaging import version # Outil pour comparer les versions\n\n# --- Callbacks Personnalisés ---\n\nclass ProgressCallback(TrainerCallback):\n    \"\"\"Callback pour afficher une barre de progression tqdm personnalisée.\"\"\"\n    def __init__(self, task_name=\"Fine-tuning\"):\n        self.task_name = task_name\n        self.progress_bar = None\n    def on_train_begin(self, args, state, control, **kwargs):\n        self.progress_bar = tqdm(total=state.max_steps, desc=self.task_name)\n    def on_step_end(self, args, state, control, **kwargs):\n        self.progress_bar.update(1)\n        if state.log_history and 'loss' in state.log_history[-1]:\n            loss_value = state.log_history[-1]['loss']\n            if loss_value is not None and not torch.isnan(torch.tensor(loss_value)):\n                self.progress_bar.set_postfix(loss=f\"{loss_value:.4f}\")\n            else:\n                self.progress_bar.set_postfix(loss=\"NaN\")\n    def on_train_end(self, args, state, control, **kwargs):\n        if self.progress_bar: self.progress_bar.close()\n\nclass NanLossStopper(TrainerCallback):\n    \"\"\"Callback pour arrêter l'entraînement si la perte devient NaN.\"\"\"\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None and 'loss' in logs and (logs['loss'] is None or torch.isnan(torch.tensor(logs['loss']))):\n            logger.error(\"Erreur fatale : Perte NaN détectée. Arrêt de l'entraînement.\")\n            control.should_training_stop = True\n\nclass PerplexityCallback(TrainerCallback):\n    \"\"\"Callback qui calcule et ajoute la perplexité aux logs après chaque évaluation.\"\"\"\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        # Cette méthode est appelée chaque fois que des logs sont créés.\n        # On vérifie si ce sont des logs d'évaluation (qui contiennent 'eval_loss').\n        if logs is not None and \"eval_loss\" in logs:\n            try:\n                # Calcul de la perplexité\n                perplexity = math.exp(logs[\"eval_loss\"])\n                # Ajout de la nouvelle métrique au dictionnaire de logs\n                logs[\"eval_perplexity\"] = perplexity\n            except OverflowError:\n                logs[\"eval_perplexity\"] = float(\"inf\")\n\n# --- Préparation du Modèle et des Données ---\nlogger.info(\"Chargement du modèle étendu pour le fine-tuning MLM...\")\nmlm_model = AutoModelForMaskedLM.from_pretrained(EXTENDED_MODEL_DIR)\nmlm_tokenizer = AutoTokenizer.from_pretrained(EXTENDED_MODEL_DIR)\n\nlogger.info(\"Préparation du dataset pour le MLM...\")\ndataset_mlm = Dataset.from_pandas(df[['message']])\ndef tokenize_function_mlm(examples):\n    return mlm_tokenizer(examples['message'], truncation=True, padding='max_length', max_length=128)\ntokenized_dataset_mlm = dataset_mlm.map(tokenize_function_mlm, batched=True, remove_columns=['message'], desc=\"Tokenizing for MLM\")\ndata_collator_mlm = DataCollatorForLanguageModeling(tokenizer=mlm_tokenizer, mlm=True, mlm_probability=0.15)\ntrain_test_split_mlm = tokenized_dataset_mlm.train_test_split(test_size=0.1, seed=42)\n\n# --- Arguments d'Entraînement avec Gestion de Compatibilité ---\ncommon_args = {\n    \"output_dir\": \"/kaggle/working/mlm_results\",\n    \"num_train_epochs\": MLM_EPOCHS,\n    \"learning_rate\": 5e-8,\n    \"per_device_train_batch_size\": 8,\n    \"gradient_accumulation_steps\": 2,\n    \"fp16\": torch.cuda.is_available(),\n    \"max_grad_norm\": 1.0,\n    \"warmup_ratio\": 0.1,\n    \"report_to\": \"none\",\n    \"load_best_model_at_end\": True,\n    \"metric_for_best_model\": \"eval_perplexity\", # La métrique que notre callback va ajouter\n    \"greater_is_better\": False, # Pour la perplexité, plus bas c'est mieux\n    \"save_total_limit\": 2,\n    \"disable_tqdm\": True,\n    \"seed\": 42\n}\n\nlogger.info(f\"Version de Transformers détectée : {transformers_version}\")\nif version.parse(transformers_version) >= version.parse(\"4.20.0\"):\n    logger.info(\"Utilisation de l'API moderne de TrainingArguments (evaluation_strategy).\")\n    training_args_mlm = TrainingArguments(**common_args, evaluation_strategy=\"epoch\", logging_strategy=\"epoch\", save_strategy=\"epoch\")\nelse:\n    logger.warning(\"Utilisation de l'API ancienne de TrainingArguments (eval_steps, logging_steps).\")\n    steps_per_epoch = len(train_test_split_mlm['train']) // (common_args['per_device_train_batch_size'] * common_args['gradient_accumulation_steps'])\n    training_args_mlm = TrainingArguments(**common_args, eval_steps=steps_per_epoch, logging_steps=steps_per_epoch, save_steps=steps_per_epoch)\n\n\n# --- Création et Lancement du Trainer ---\ntrainer_mlm = Trainer(\n    model=mlm_model,\n    args=training_args_mlm,\n    train_dataset=train_test_split_mlm['train'],\n    eval_dataset=train_test_split_mlm['test'],\n    data_collator=data_collator_mlm,\n    callbacks=[\n        EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01),\n        ProgressCallback(task_name=\"Fine-tuning (MLM)\"),\n        NanLossStopper(),\n        PerplexityCallback() # Le callback qui va ajouter la métrique\n    ]\n)\n\nlogger.info(\"Début du fine-tuning MLM (avec calcul de perplexité via Callback)...\")\ntrainer_mlm.train()\n\n\n# --- SAUVEGARDE ET VISUALISATION DES MÉTRIQUES ---\nlogger.info(f\"Sauvegarde du meilleur modèle adapté par MLM dans : {ADAPTED_LM_DIR}\")\ntrainer_mlm.save_model(ADAPTED_LM_DIR)\nmlm_tokenizer.save_pretrained(ADAPTED_LM_DIR)\nlogger.info(\"Phase 1 (Adaptation du langage) terminée.\")\n\nlog_history = trainer_mlm.state.log_history\ndf_log = pd.DataFrame(log_history)\n\nif not df_log.empty:\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n    fig.suptitle(\"Performances du Fine-Tuning MLM\", fontsize=16)\n    \n    train_logs = df_log[df_log['loss'].notna()].copy()\n    eval_logs = df_log[df_log['eval_loss'].notna()].copy()\n\n    if not train_logs.empty and not eval_logs.empty:\n        axes[0].plot(train_logs['epoch'], train_logs['loss'], marker='o', label=\"Training Loss\")\n        axes[0].plot(eval_logs['epoch'], eval_logs['eval_loss'], marker='o', label=\"Validation Loss\")\n        axes[0].set_title(\"Perte (Loss)\"); axes[0].set_xlabel(\"Époque\"); axes[0].set_ylabel(\"Perte\"); axes[0].grid(True); axes[0].legend()\n    else:\n        axes[0].set_title(\"Perte (Loss) - Données insuffisantes\")\n\n    if 'eval_perplexity' in eval_logs.columns:\n        axes[1].plot(eval_logs['epoch'], eval_logs['eval_perplexity'], marker='o', color='green', label=\"Validation Perplexity\")\n        axes[1].set_title(\"Perplexité sur l'ensemble de validation\")\n        axes[1].set_xlabel(\"Époque\"); axes[1].set_ylabel(\"Perplexité (plus bas = meilleur)\"); axes[1].grid(True); axes[1].legend()\n    else:\n        axes[1].set_title(\"Perplexité - Données non trouvées\")\n        axes[1].text(0.5, 0.5, \"'eval_perplexity' non trouvé dans les logs.\", ha='center', va='center')\n        logger.warning(\"La métrique 'eval_perplexity' n'a pas été trouvée, le graphique ne sera pas généré.\")\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\n    best_metrics = getattr(trainer_mlm.state, 'best_metric', None)\n    if best_metrics:\n        logger.info(f\"Meilleure performance MLM atteinte : Perplexité = {best_metrics:.4f}\")\nelse:\n    logger.warning(\"Aucun log d'entraînement n'a été généré.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 1.3 : Visualisation des Résultats MLM ---\nlogger.info(\"Génération du graphique de perte pour la phase MLM...\")\nlog_history_mlm = trainer_mlm.state.log_history\ndf_log_mlm = pd.DataFrame(log_history_mlm)\n\ntrain_loss_df = df_log_mlm[df_log_mlm['loss'].notna()]\neval_loss_df = df_log_mlm[df_log_mlm['eval_loss'].notna()]\n\nif not train_loss_df.empty and not eval_loss_df.empty:\n    plt.figure(figsize=(12, 6))\n    plt.plot(train_loss_df['epoch'], train_loss_df['loss'], marker='o', linestyle='-', label=\"Training Loss\")\n    plt.plot(eval_loss_df['epoch'], eval_loss_df['eval_loss'], marker='o', linestyle='-', label=\"Validation Loss\")\n    plt.title(\"Perte durant l'entraînement MLM (Phase 1)\")\n    plt.xlabel(\"Époque\")\n    plt.ylabel(\"Perte (Loss)\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\nelse:\n    logger.warning(\"Impossible de générer le graphique de perte MLM. Données de log insuffisantes.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 1.3 (Révisée) : Clustering Forcé à k=2 et Évaluation avec Étiquettes Réelles ---\n\n# Imports nécessaires pour cette cellule\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nlogger.info(\"Début de l'évaluation des embeddings par clustering K-Means (k=2) et comparaison avec les étiquettes réelles.\")\n\n# --- 1. Génération des Embeddings 768D pour l'ENSEMBLE du Dataset ---\nlogger.info(\"Chargement du modèle et du tokenizer adaptés...\")\n# Assurez-vous que ADAPTED_LM_DIR et df sont définis dans les cellules précédentes\nmodel = AutoModel.from_pretrained(ADAPTED_LM_DIR)\ntokenizer = AutoTokenizer.from_pretrained(ADAPTED_LM_DIR)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\nmodel.eval()\n\nsentences = df['message'].tolist()\n# Récupérer les étiquettes réelles pour l'évaluation finale\ntrue_labels = df['vote_final'].values \n\nbatch_size = 32\nall_embeddings = []\n\nlogger.info(f\"Génération des embeddings pour {len(sentences)} phrases...\")\nfor i in tqdm(range(0, len(sentences), batch_size), desc=\"Generating Embeddings (768D)\"):\n    batch_sentences = sentences[i:i+batch_size]\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n        attention_mask = inputs['attention_mask']\n        mask_expanded = attention_mask.unsqueeze(-1).expand(outputs.last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(outputs.last_hidden_state * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        batch_embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n        all_embeddings.append(batch_embeddings)\n\nembeddings_full_768d = np.concatenate(all_embeddings, axis=0)\nlogger.info(\"Normalisation des embeddings 768D...\")\nscaled_embeddings_full_768d = StandardScaler().fit_transform(embeddings_full_768d)\n\n\n# --- 2. Clustering avec Mini-Batch K-Means (k=2) sur les Données 768D ---\nn_clusters = 2\nlogger.info(f\"Application de l'algorithme Mini-Batch K-Means pour trouver exactement {n_clusters} clusters...\")\nkmeans = MiniBatchKMeans(\n    n_clusters=n_clusters,\n    random_state=42,\n    n_init='auto',\n    batch_size=256\n)\npredicted_clusters = kmeans.fit_predict(scaled_embeddings_full_768d)\n\n\n# --- 3. Réduction de Dimensionnalité avec t-SNE (pour la visualisation) ---\nlogger.info(\"Réduction de la dimensionnalité de 768D à 2D avec t-SNE (peut prendre du temps)...\")\ntsne = TSNE(\n    n_components=2, \n    perplexity=30, \n    metric='cosine', \n    random_state=42,\n    n_jobs=-1\n)\nembeddings_2d_for_viz = tsne.fit_transform(embeddings_full_768d)\n\n\n# --- 4. Évaluation du Clustering en Comparaison avec les Étiquettes Réelles ---\nprint(\"\\n\" + \"=\"*60)\nprint(\"--- RÉSULTATS DU CLUSTERING K-MEANS (k=2) vs ÉTIQUETTES RÉELLES ---\")\n\n# a) Métrique interne (qualité des clusters formés)\nsilhouette_avg = silhouette_score(scaled_embeddings_full_768d, predicted_clusters)\nprint(f\"Score de Silhouette (qualité intrinsèque des clusters) : {silhouette_avg:.4f}\")\n\n# b) Métriques externes (comparaison avec les étiquettes réelles)\nari_score = adjusted_rand_score(true_labels, predicted_clusters)\nnmi_score = normalized_mutual_info_score(true_labels, predicted_clusters)\nprint(f\"Adjusted Rand Score (ARI) : {ari_score:.4f}\")\nprint(f\"Normalized Mutual Information (NMI) : {nmi_score:.4f}\")\nprint(\"\\n(Pour ARI et NMI, 1.0 = correspondance parfaite entre clusters et étiquettes, 0.0 = aucune correspondance)\")\nprint(\"=\"*60 + \"\\n\")\n\n\n# --- 5. Visualisation Comparative ---\nlogger.info(\"Génération de la visualisation comparative des clusters...\")\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\nfig.suptitle(\"Comparaison entre Étiquettes Réelles et Clusters K-Means (k=2)\", fontsize=20)\n\n# Graphique 1 : Coloration par ÉTIQUETTES RÉELLES\nsns.scatterplot(\n    x=embeddings_2d_for_viz[:, 0], \n    y=embeddings_2d_for_viz[:, 1],\n    hue=true_labels, # <-- Utilise les vraies étiquettes\n    palette=\"viridis\", \n    s=10, alpha=0.7, ax=ax1, legend='full'\n)\nax1.set_title(\"1. Visualisation selon les Étiquettes Réelles\", fontsize=16)\nax1.set_xlabel(\"Composante t-SNE 1\")\nax1.set_ylabel(\"Composante t-SNE 2\")\nax1.grid(True, linestyle='--', alpha=0.6)\n\n# Graphique 2 : Coloration par CLUSTERS PRÉDITS\nsns.scatterplot(\n    x=embeddings_2d_for_viz[:, 0], \n    y=embeddings_2d_for_viz[:, 1],\n    hue=predicted_clusters, # <-- Utilise les 2 clusters trouvés par K-Means\n    palette=\"plasma\", \n    s=10, alpha=0.7, ax=ax2, legend='full'\n)\nax2.set_title(\"2. Visualisation selon les 2 Clusters Prédits\", fontsize=16)\nax2.set_xlabel(\"Composante t-SNE 1\")\nax2.set_ylabel(\"Composante t-SNE 2\")\nax2.grid(True, linestyle='--', alpha=0.6)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 2 : Fine-Tuning pour la Classification\n\nMaintenant que notre modèle comprend notre vocabulaire spécifique, nous allons l'entraîner à la tâche finale : classifier les messages comme \"hateful\" ou \"not_hateful\".\n\n### Étape 2.1 : Préparation des données\n\nNous devons préparer les données en associant chaque message à son étiquette numérique, puis en les divisant en ensembles d'entraînement et de test.","metadata":{}},{"cell_type":"code","source":"# --- ÉTAPE DE NETTOYAGE : Libérer l'espace disque ---\nimport shutil\nimport os\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nmlm_results_dir = \"/kaggle/working/mlm_results\"\n\nif os.path.exists(mlm_results_dir):\n    logger.info(f\"Nettoyage de l'espace disque en supprimant les checkpoints MLM intermédiaires de '{mlm_results_dir}'...\")\n    try:\n        shutil.rmtree(mlm_results_dir)\n        logger.info(\"Nettoyage terminé avec succès.\")\n    except OSError as e:\n        logger.error(f\"Erreur lors de la suppression du dossier {mlm_results_dir}: {e}\")\n        # Alternative plus forcée si la première échoue\n        !rm -rf {mlm_results_dir}\nelse:\n    logger.info(\"Le dossier des résultats MLM n'existe pas, pas de nettoyage nécessaire.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 2.1 : Préparation et Tokenization des Données de Classification ---\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\n\nlogger.info(\"Phase 2 : Préparation des données pour la Classification.\")\n\n# --- Mappage des Labels ---\ndf['vote_final'] = df['vote_final'].astype(str)\nlabels_list = sorted(df['vote_final'].unique())\nlabel2id = {label: i for i, label in enumerate(labels_list)}\nid2label = {i: label for label, i in label2id.items()}\ndf['labels'] = df['vote_final'].map(label2id)\nlogger.info(f\"Mappage des labels créé : {label2id}\")\n\n# --- Division en Train / Validation / Test ---\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'])\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['labels'])\nlogger.info(f\"Taille des ensembles - Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n\n# --- Rééquilibrage par Sursampling (Oversampling) ---\nlogger.info(\"Rééquilibrage de l'ensemble d'entraînement...\")\ntry:\n    if len(train_df['labels'].value_counts()) > 1:\n        majority_class_id = train_df['labels'].value_counts().idxmax()\n        df_majority = train_df[train_df.labels == majority_class_id]\n        df_minority = train_df[train_df.labels != majority_class_id]\n        df_minority_oversampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n        train_df_balanced = pd.concat([df_majority, df_minority_oversampled])\n        logger.info(f\"Distribution après rééquilibrage:\\n{train_df_balanced['vote_final'].value_counts()}\")\n    else:\n        logger.warning(\"Une seule classe détectée dans le jeu d'entraînement, pas de rééquilibrage effectué.\")\n        train_df_balanced = train_df\nexcept Exception as e:\n    logger.error(f\"Erreur pendant le rééquilibrage : {e}. Utilisation du jeu de données original.\")\n    train_df_balanced = train_df\n\n# --- Création des Datasets Hugging Face ---\ntrain_dataset = Dataset.from_pandas(train_df_balanced)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n# --- Tokenization ---\nlogger.info(f\"Chargement du tokenizer adapté depuis {ADAPTED_LM_DIR}...\")\nclassifier_tokenizer = AutoTokenizer.from_pretrained(ADAPTED_LM_DIR)\n\ndef tokenize_function_classifier(examples):\n    return classifier_tokenizer(examples['message'], truncation=True, padding='max_length', max_length=128)\n\ncolumns_to_remove = ['message', 'vote_final'] # On garde 'labels' !\ntrain_tokenized = train_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\nval_tokenized = val_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\ntest_tokenized = test_dataset.map(tokenize_function_classifier, batched=True, remove_columns=columns_to_remove)\n\nlogger.info(\"Préparation des données de classification terminée.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Étape 2.2 : Entraînement du Classifieur\n\nNous chargeons le modèle que nous avons adapté en Phase 1. Il connaît déjà notre vocabulaire. Nous le chargeons maintenant avec une tête de classification (`AutoModelForSequenceClassification`) et nous le fine-tunons sur nos données étiquetées.","metadata":{}},{"cell_type":"code","source":"# --- Étape 2.2 : Préparation du Modèle de Classification (Congélation) ---\nfrom transformers import AutoModelForSequenceClassification\n\nlogger.info(f\"Chargement du modèle adapté depuis : {ADAPTED_LM_DIR}\")\nclassifier_model = AutoModelForSequenceClassification.from_pretrained(\n    ADAPTED_LM_DIR,\n    num_labels=len(label2id),\n    id2label=id2label,\n    label2id=label2id\n)\n\n# --- CORRECTION PRINCIPALE : Utiliser 'roberta' au lieu de 'distilbert' ---\n# Le modèle de base pour CamemBERT s'appelle 'roberta' en interne.\nlogger.info(\"Congélation du corps du Transformer pour le fine-tuning initial...\")\n\n# On gèle toutes les couches du corps du modèle\nfor param in classifier_model.roberta.parameters():\n    param.requires_grad = False\n\n# MAIS, on s'assure que la couche d'embedding reste entraînable pour qu'elle continue de s'adapter.\n# Les embeddings font partie de 'roberta', donc on accède via `roberta.embeddings`\nfor param in classifier_model.roberta.embeddings.parameters():\n    param.requires_grad = True\n\n# La tête de classification (classifier_model.classifier) est automatiquement\n# entraînable car elle est nouvelle et ses paramètres ont `requires_grad=True` par défaut.\n\n# --- Vérification (inchangée) ---\ntrainable_params = sum(p.numel() for p in classifier_model.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in classifier_model.parameters())\nlogger.info(f\"Paramètres entraînables (phase 1) : {trainable_params} / {total_params} ({100 * trainable_params / total_params:.2f}%)\")\n# Le log devrait maintenant s'afficher correctement, montrant que seul un petit pourcentage\n# des poids est prêt à être entraîné.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Le code ci-dessous est CORRECT et fonctionnera après la mise à jour de l'environnement.\n\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score\nfrom transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n\n# ASSUREZ-VOUS QUE `label2id` EST DISPONIBLE ET CONTIENT BIEN LE MAPPING\nhateful_class_id = label2id.get('hateful')\nif hateful_class_id is None:\n    hateful_class_id = 1\n    logger.warning(f\"Label 'hateful' non trouvé dans label2id. Utilisation de l'ID {hateful_class_id} comme classe positive par défaut.\")\n\n# Fonction de calcul des métriques, maintenant centrée sur le rappel\ndef compute_metrics_cls(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    recall_hateful = recall_score(labels, predictions, pos_label=hateful_class_id, zero_division=0)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1\": f1_score(labels, predictions, average='weighted', zero_division=0),\n        \"recall_hateful\": recall_hateful\n    }\n\n# Arguments d'entraînement avec Early Stopping basé sur le RAPPEL\ntraining_args_phase1 = TrainingArguments(\n    output_dir=\"/kaggle/working/classifier_results_phase1\",\n    num_train_epochs=15,\n    learning_rate=5e-4,\n    per_device_train_batch_size=BATCH_SIZE,\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,\n    fp16=True,\n    \n    # Ces arguments sont maintenant reconnus par la nouvelle version de la bibliothèque\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    \n    load_best_model_at_end=True, \n    metric_for_best_model=\"recall_hateful\",\n    greater_is_better=True,\n    \n    report_to=\"none\"\n)\n\n# Création du Trainer\ntrainer_phase1 = Trainer(\n    model=classifier_model,\n    args=training_args_phase1,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=classifier_tokenizer,\n    compute_metrics=compute_metrics_cls,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\nlogger.info(\"Début de la phase 1 de fine-tuning (optimisation du rappel)...\")\ntrainer_phase1.train()\n\nlogger.info(\"Phase 1 de fine-tuning (rappel) terminée.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Étape 2.4 : Décongélation et Fine-Tuning Final (Modèle Complet, optimisé pour le Rappel) ---\nlogger.info(\"Décongélation de toutes les couches pour le fine-tuning final...\")\nfor param in classifier_model.parameters():\n    param.requires_grad = True\nlogger.info(\"Tous les paramètres sont maintenant entraînables.\")\n\n# Arguments pour le fine-tuning final avec un learning rate très bas\ntraining_args_final = TrainingArguments(\n    output_dir=\"/kaggle/working/classifier_results_final\",\n    num_train_epochs=10, # Limite maximale d'époques\n    \n    # Taux d'apprentissage très bas pour un affinage de précision\n    learning_rate=2e-5, \n    \n    per_device_train_batch_size=BATCH_SIZE, # Assurez-vous que BATCH_SIZE est défini\n    weight_decay=0.01,\n    max_grad_norm=1.0,\n    lr_scheduler_type='cosine',\n    warmup_ratio=0.1,\n    fp16=True,\n    \n    # Mêmes stratégies que précédemment\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    report_to=\"none\",\n    \n    # --- CHANGEMENT PRINCIPAL ICI ---\n    load_best_model_at_end=True,\n    metric_for_best_model=\"recall_hateful\", # On continue de surveiller le rappel\n    greater_is_better=True\n)\n\n# On crée un nouveau Trainer pour cette phase finale.\n# Il utilise la même fonction `compute_metrics_cls` que précédemment.\ntrainer_final = Trainer(\n    model=classifier_model, # Le modèle a maintenant toutes ses couches dégelées\n    args=training_args_final,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=classifier_tokenizer,\n    compute_metrics=compute_metrics_cls,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] # Patience plus courte pour la phase d'affinage\n)\n\nlogger.info(\"Début du fine-tuning final (modèle complet, optimisation du rappel)...\")\ntrainer_final.train()\n\n# --- SAUVEGARDE DU MODÈLE FINAL ---\n# `trainer_final.model` contient maintenant la meilleure version du modèle complet,\n# basée sur le RAPPEL de la classe haineuse.\nlogger.info(f\"Sauvegarde du meilleur modèle final (optimisé pour le rappel) dans : {FINAL_CLASSIFIER_DIR}\")\ntrainer_final.save_model(FINAL_CLASSIFIER_DIR)\nclassifier_tokenizer.save_pretrained(FINAL_CLASSIFIER_DIR)\n\nlogger.info(\"Phase 2 (Fine-tuning de classification) terminée avec succès.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Étape 2.3 : Évaluation, Visualisation et Sauvegarde du Modèle Final\n\nL'entraînement est terminé. Il est temps d'analyser en détail les performances de notre modèle fine-tuné. Nous allons :\n1.  Sauvegarder le meilleur modèle et son tokenizer.\n2.  Visualiser les courbes d'apprentissage pour confirmer que l'entraînement s'est bien déroulé.\n3.  Calculer les métriques de performance (précision, rappel, F1-score).\n4.  Afficher une matrice de confusion pour comprendre les types d'erreurs que le modèle commet.","metadata":{}},{"cell_type":"code","source":"# --- Étape 2.5 : Évaluation Finale et Visualisation ---\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nlogger.info(\"Évaluation finale sur le jeu de test (données jamais vues)...\")\npredictions_output = trainer_final.predict(test_tokenized)\ny_preds = predictions_output.predictions.argmax(axis=1)\ny_true = test_tokenized['labels']\n\n# Rapport de classification (Précision, Rappel, F1-Score)\nprint(\"\\n\" + \"=\"*50)\nprint(\"--- Rapport de Classification Final ---\")\ntarget_names_ordered = [id2label[i] for i in sorted(id2label.keys())]\nprint(classification_report(y_true, y_preds, target_names=target_names_ordered))\nprint(\"=\"*50 + \"\\n\")\n\n# Matrice de confusion\ncm = confusion_matrix(y_true, y_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names_ordered, yticklabels=target_names_ordered)\nplt.title(\"Matrice de Confusion du Modèle Final sur le Jeu de Test\")\nplt.xlabel(\"Étiquette Prédite\")\nplt.ylabel(\"Étiquette Vraie\")\nplt.show()\n\n# --- Visualisation des courbes d'entraînement de la dernière phase ---\nlog_history_cls = trainer_final.state.log_history\ndf_log_cls = pd.DataFrame(log_history_cls)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\nfig.suptitle(\"Performances du Fine-Tuning Final (Phase 2.4)\", fontsize=16)\n\n# Filtrer les données pour les graphiques\ntrain_loss_cls = df_log_cls[df_log_cls['loss'].notna()]\neval_loss_cls = df_log_cls[df_log_cls['eval_loss'].notna()]\neval_acc_cls = df_log_cls[df_log_cls['eval_f1'].notna()] # On affiche le F1-score\n\n# Graphique de la Perte\nif not eval_loss_cls.empty:\n    ax1.plot(train_loss_cls['epoch'], train_loss_cls['loss'], marker='o', label=\"Training Loss\")\n    ax1.plot(eval_loss_cls['epoch'], eval_loss_cls['eval_loss'], marker='o', label=\"Validation Loss\")\n    ax1.set_title(\"Perte (Loss)\")\n    ax1.set_xlabel(\"Époque\"); ax1.set_ylabel(\"Perte\"); ax1.grid(True); ax1.legend()\n\n# Graphique du F1-score\nif not eval_acc_cls.empty:\n    ax2.plot(eval_acc_cls['epoch'], eval_acc_cls['eval_f1'], marker='o', color='purple', label=\"Validation F1-Score\")\n    ax2.set_title(\"F1-Score\")\n    ax2.set_xlabel(\"Époque\"); ax2.set_ylabel(\"F1-Score\"); ax2.grid(True); ax2.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Étape 2.4 : Test sur des Exemples Concrets avec une Pipeline\n\nLa méthode la plus simple pour utiliser notre modèle est de le charger dans une `pipeline` Hugging Face. Cela s'occupe de toute la pré-traitement et du post-traitement pour nous.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Charger le modèle final dans une pipeline pour un test facile\nlogger.info(\"Chargement de la pipeline avec le modèle final...\")\n# S'assurer d'utiliser le GPU s'il est disponible\ndevice = 0 if torch.cuda.is_available() else -1\nfinal_pipe = pipeline(\"text-classification\", model=FINAL_CLASSIFIER_DIR, device=device)\n\n# Exemples de test\ntest_phrases = [\n    \"Je te déteste, tu n'es qu'un idiot.\",\n    \"Passe une excellente journée, merci pour ton aide !\",\n    \"Ce nkwada pense qu'il peut nous tromper.\", # Exemple avec vocabulaire spécifique\n    \"C'est une honte pour notre pays.\",\n    \"Arrête de dire des bêtises, tu es nul\",\n    \"tu es deguelasse\",\n    \"c'est pitoyable\",\n]\n\nlogger.info(\"\\n--- Test du modèle final sur des exemples concrets ---\")\nfor phrase in test_phrases:\n    result = final_pipe(phrase)\n    print(f\"Phrase: '{phrase}'\\nPrédiction: {result}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# S'assurer que la pipeline est bien chargée\ntry:\n    final_pipe\nexcept NameError:\n    from transformers import pipeline\n    logger.info(\"Rechargement de la pipeline pour l'interface interactive...\")\n    device = 0 if torch.cuda.is_available() else -1\n    final_pipe = pipeline(\"text-classification\", model=FINAL_CLASSIFIER_DIR, device=device)\n\ndef classify_interactive():\n    \"\"\"Lance une boucle de classification interactive.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"      Interface de Classification de Discours Haineux\")\n    print(\"=\"*60)\n    print(\"Entrez une phrase à analyser. Tapez 'quitter' pour arrêter.\")\n    print(\"-\" * 60)\n\n    while True:\n        # Demander une phrase à l'utilisateur\n        user_input = input(\"Votre phrase > \")\n\n        # Condition de sortie\n        if user_input.lower() == 'quitter':\n            print(\"Au revoir !\")\n            break\n        \n        # Vérifier que l'input n'est pas vide\n        if not user_input.strip():\n            print(\"Veuillez entrer une phrase non vide.\")\n            continue\n\n        # Faire la prédiction avec la pipeline\n        result = final_pipe(user_input)[0] # On prend le premier élément de la liste\n        label = result['label']\n        score = result['score']\n\n        # Afficher le résultat de manière lisible\n        print(f\"  -> Prédiction : '{label}' (Confiance : {score:.2%})\")\n        print(\"-\" * 60)\n\n# Lancer l'interface interactive\nclassify_interactive()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}